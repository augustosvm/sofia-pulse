#!/usr/bin/env python3
"""
Sofia Pulse - Premium Insights v4.0 FINAL
USA OS DADOS REAIS coletados pelos collectors
+ GEO-LOCALIZAÃ‡ÃƒO (continentes, paÃ­ses, universidades)
"""

import psycopg2
from datetime import datetime
import os
from collections import defaultdict, Counter

# Config
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': os.getenv('DB_PORT', '5432'),
    'database': os.getenv('DB_NAME', 'sofia_db'),
    'user': os.getenv('DB_USER', 'sofia'),
    'password': os.getenv('DB_PASSWORD', 'sofia123strong')
}

# ============================================================================
# MAPEAMENTOS GEOGRÃFICOS (da v2.0)
# ============================================================================

# Mapeamento de categorias ArXiv para nomes legÃ­veis
ARXIV_CATEGORIES = {
    'cs.AI': 'InteligÃªncia Artificial',
    'cs.LG': 'Machine Learning',
    'cs.CV': 'VisÃ£o Computacional',
    'cs.CL': 'Processamento de Linguagem Natural (NLP)',
    'cs.RO': 'RobÃ³tica',
    'cs.NE': 'ComputaÃ§Ã£o Neural e Evolutiva',
    'cs.MA': 'Sistemas Multi-Agente',
    'cs.HC': 'InteraÃ§Ã£o Humano-Computador',
    'cs.IR': 'RecuperaÃ§Ã£o de InformaÃ§Ã£o',
    'cs.CR': 'Criptografia e SeguranÃ§a',
    'stat.ML': 'Machine Learning (EstatÃ­stica)',
    'math.OC': 'OtimizaÃ§Ã£o e Controle',
    'q-bio': 'Biologia Quantitativa',
    'eess.IV': 'Processamento de Imagens',
    'eess.AS': 'Processamento de Ãudio',
}

def translate_category(cat):
    """Traduz categoria ArXiv para portuguÃªs"""
    return ARXIV_CATEGORIES.get(cat, cat)

# Mapeamento de paÃ­ses para continentes
CONTINENTS = {
    # AmÃ©rica do Norte
    'USA': 'AmÃ©rica do Norte', 'US': 'AmÃ©rica do Norte', 'United States': 'AmÃ©rica do Norte',
    'Canada': 'AmÃ©rica do Norte', 'MÃ©xico': 'AmÃ©rica do Norte', 'Mexico': 'AmÃ©rica do Norte',

    # AmÃ©rica do Sul
    'Brazil': 'AmÃ©rica do Sul', 'Brasil': 'AmÃ©rica do Sul', 'BR': 'AmÃ©rica do Sul',
    'Argentina': 'AmÃ©rica do Sul', 'Chile': 'AmÃ©rica do Sul', 'Colombia': 'AmÃ©rica do Sul',
    'Peru': 'AmÃ©rica do Sul', 'Venezuela': 'AmÃ©rica do Sul', 'Uruguay': 'AmÃ©rica do Sul',

    # Europa
    'UK': 'Europa', 'United Kingdom': 'Europa', 'England': 'Europa', 'Germany': 'Europa',
    'France': 'Europa', 'Spain': 'Europa', 'Italy': 'Europa', 'Netherlands': 'Europa',
    'Switzerland': 'Europa', 'Sweden': 'Europa', 'Norway': 'Europa', 'Denmark': 'Europa',
    'Finland': 'Europa', 'Poland': 'Europa', 'Portugal': 'Europa', 'Ireland': 'Europa',

    # Ãsia
    'China': 'Ãsia', 'India': 'Ãsia', 'Japan': 'Ãsia', 'South Korea': 'Ãsia',
    'Singapore': 'Ãsia', 'Taiwan': 'Ãsia', 'Hong Kong': 'Ãsia', 'Israel': 'Ãsia',
    'UAE': 'Ãsia', 'Saudi Arabia': 'Ãsia', 'Thailand': 'Ãsia', 'Indonesia': 'Ãsia',

    # Oceania
    'Australia': 'Oceania', 'New Zealand': 'Oceania',

    # Ãfrica
    'South Africa': 'Ãfrica', 'Nigeria': 'Ãfrica', 'Kenya': 'Ãfrica', 'Egypt': 'Ãfrica',
}

# Universidades reconhecidas e suas especializaÃ§Ãµes
UNIVERSITIES = {
    # USA
    'MIT': ('USA', ['AI', 'Robotics', 'Computer Science']),
    'Stanford': ('USA', ['AI', 'Biotech', 'Clean Energy']),
    'Harvard': ('USA', ['Medicine', 'Biotech', 'Business']),
    'Berkeley': ('USA', ['AI', 'Quantum', 'Climate']),
    'CMU': ('USA', ['AI', 'Robotics', 'HCI']),
    'Caltech': ('USA', ['Physics', 'Space', 'Quantum']),

    # China
    'Tsinghua': ('China', ['AI', 'Manufacturing', 'Engineering']),
    'Peking': ('China', ['AI', 'Chemistry', 'Materials']),

    # Europa
    'Oxford': ('UK', ['Medicine', 'AI', 'Climate']),
    'Cambridge': ('UK', ['Physics', 'Biotech', 'AI']),
    'ETH': ('Switzerland', ['Robotics', 'Quantum', 'Climate']),

    # Brasil
    'USP': ('Brasil', ['Agro-tech', 'Medicine', 'Engineering']),
    'Unicamp': ('Brasil', ['Agro-tech', 'Materials', 'Energy']),
    'UFRJ': ('Brasil', ['Oil & Gas', 'Ocean', 'Medicine']),
    'UFMG': ('Brasil', ['Mining', 'Materials', 'AI']),
    'ITA': ('Brasil', ['Aerospace', 'Defense Tech', 'Engineering']),
    'UFRGS': ('Brasil', ['AI', 'Agro-tech', 'Materials']),

    # Outras
    'Technion': ('Israel', ['Defense Tech', 'AI', 'Cybersecurity']),
    'NUS': ('Singapore', ['AI', 'Fintech', 'Smart Cities']),
}

# EspecializaÃ§Ã£o por regiÃ£o
REGIONAL_SPECIALIZATIONS = {
    'Brasil': ['Agro-tech', 'Fintech', 'Healthcare', 'Ed-tech'],
    'USA': ['AI', 'SaaS', 'Biotech', 'Space'],
    'China': ['AI', 'Manufacturing', 'Hardware', 'E-commerce'],
    'Europa': ['Green Tech', 'Privacy Tech', 'Mobility', 'Deep Tech'],
    'Israel': ['Cybersecurity', 'Defense Tech', 'AI', 'Biotech'],
    'India': ['Software', 'Fintech', 'Ed-tech', 'Healthcare'],
    'Singapore': ['Fintech', 'Smart Cities', 'Logistics', 'Biotech'],
}

def extract_country_from_text(text):
    """Extrai paÃ­s/universidade de um texto (autores, empresa, etc)"""
    if not text:
        return None, None

    text_lower = str(text).lower()

    # Primeiro procura universidades
    for uni, (country, specs) in UNIVERSITIES.items():
        if uni.lower() in text_lower:
            return country, uni

    # Depois procura paÃ­ses
    for country in CONTINENTS.keys():
        if country.lower() in text_lower:
            return country, None

    return None, None

def get_continent(country):
    """Retorna continente do paÃ­s"""
    return CONTINENTS.get(country, 'Outros')

# ============================================================================

conn = psycopg2.connect(**DB_CONFIG)
cur = conn.cursor()

os.makedirs('analytics/premium-insights', exist_ok=True)

print("ğŸ“Š Coletando TODOS os dados...")

# 1. ARXIV PAPERS
cur.execute("""
    SELECT arxiv_id, title, authors, categories, published_date, abstract
    FROM arxiv_ai_papers
    ORDER BY published_date DESC
    LIMIT 50
""")
papers = cur.fetchall()
print(f"   ğŸ“š ArXiv Papers: {len(papers)}")

# 2. FUNDING ROUNDS
cur.execute("""
    SELECT company_name, sector, amount_usd, valuation_usd, round_type, announced_date
    FROM sofia.funding_rounds
    ORDER BY announced_date DESC
    LIMIT 50
""")
funding = cur.fetchall()
print(f"   ğŸ’° Funding Rounds: {len(funding)}")

# 3. AI COMPANIES
cur.execute("""
    SELECT name, country, category, total_funding_usd, employee_count, founded_year
    FROM ai_companies
    ORDER BY total_funding_usd DESC NULLS LAST
    LIMIT 50
""")
companies = cur.fetchall()
print(f"   ğŸš€ AI Companies: {len(companies)}")

# 4. EPO PATENTS
cur.execute("""
    SELECT title, applicant, filing_date, ipc_classification
    FROM epo_patents
    ORDER BY filing_date DESC
    LIMIT 50
""")
patents_epo = cur.fetchall()
print(f"   ğŸ“œ EPO Patents: {len(patents_epo)}")

# 5. WIPO CHINA PATENTS
cur.execute("""
    SELECT title, applicant, filing_date, ipc_classification
    FROM wipo_china_patents
    ORDER BY filing_date DESC
    LIMIT 50
""")
patents_china = cur.fetchall()
print(f"   ğŸ‡¨ğŸ‡³ WIPO China Patents: {len(patents_china)}")

# 6. OPENALEX PAPERS
cur.execute("""
    SELECT title, authors, publication_date, cited_by_count
    FROM openalex_papers
    ORDER BY cited_by_count DESC NULLS LAST
    LIMIT 50
""")
openalex = cur.fetchall()
print(f"   ğŸ“– OpenAlex Papers: {len(openalex)}")

# 7. B3
cur.execute("""
    WITH latest AS (
        SELECT ticker, company, price, change_pct, sector,
               ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY collected_at DESC) as rn
        FROM market_data_brazil
    )
    SELECT ticker, company, price, change_pct, sector
    FROM latest WHERE rn = 1
    ORDER BY change_pct DESC
""")
b3 = cur.fetchall()
print(f"   ğŸ“ˆ B3: {len(b3)}")

print("\nğŸ’ Gerando insights...\n")

# GERAR INSIGHTS
insights = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ğŸŒ SOFIA PULSE - PREMIUM INSIGHTS v4.0
   Data: {datetime.now().strftime('%Y-%m-%d %H:%M')}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š DADOS COLETADOS:
- {len(papers)} papers ArXiv (AI/ML)
- {len(openalex)} papers OpenAlex (global)
- {len(patents_epo)} patents EPO (Europa)
- {len(patents_china)} patents WIPO China
- {len(funding)} funding rounds
- {len(companies)} AI companies
- {len(b3)} aÃ§Ãµes B3


ğŸ”¬ PAPERS ACADÃŠMICOS (ArXiv AI/ML)
-------------------------------------------------------------------

ğŸ”¥ TOP PAPERS RECENTES:

"""

for arxiv_id, title, authors, cats, pub_date, abstract in papers[:10]:
    authors_str = ', '.join(authors[:3]) if authors else 'N/A'
    # Traduzir categorias
    cats_translated = [translate_category(c) for c in cats[:3]] if cats else ['N/A']
    cats_str = ', '.join(cats_translated)
    insights += f"   ğŸ“„ {title}\n"
    insights += f"      Autores: {authors_str}\n"
    insights += f"      Categorias: {cats_str}\n"
    insights += f"      Data: {pub_date}\n\n"

# AnÃ¡lise por categoria
if papers:
    from collections import Counter
    all_cats = []
    for _, _, _, cats, _, _ in papers:
        if cats:
            all_cats.extend(cats)

    top_cats = Counter(all_cats).most_common(10)
    insights += "\nğŸ“Š TOP CATEGORIAS DE PESQUISA:\n\n"
    for cat, count in top_cats:
        cat_translated = translate_category(cat)
        insights += f"   {cat_translated:45s} | {count:3d} papers\n"

insights += "\n\nğŸš€ AI COMPANIES GLOBAIS\n"
insights += "-------------------------------------------------------------------\n\n"

if companies:
    # Por paÃ­s
    from collections import defaultdict
    by_country = defaultdict(list)
    for name, country, category, comp_funding, employees, year in companies:
        by_country[country or 'Unknown'].append((name, category, comp_funding))

    insights += "ğŸŒ EMPRESAS DE IA POR PAÃS:\n\n"
    for country, comps in sorted(by_country.items(), key=lambda x: len(x[1]), reverse=True)[:10]:
        insights += f"   {country}: {len(comps)} empresas\n"
        for name, cat, comp_funding in comps[:3]:
            funding_m = comp_funding / 1_000_000 if comp_funding else 0
            insights += f"      â€¢ {name} ({cat}) - ${funding_m:.1f}M funding\n"
        insights += "\n"

insights += "\nğŸ“œ PATENTS (Europa + China)\n"
insights += "-------------------------------------------------------------------\n\n"

insights += f"ğŸ‡ªğŸ‡º EPO (Europa): {len(patents_epo)} patents recentes\n"
insights += f"ğŸ‡¨ğŸ‡³ WIPO China: {len(patents_china)} patents recentes\n\n"

if patents_epo:
    insights += "ğŸ”¥ TOP PATENTS EPO:\n\n"
    for title, applicant, date, ipc_class in patents_epo[:5]:
        appl_str = applicant if applicant else 'N/A'
        insights += f"   â€¢ {title}\n"
        insights += f"     Empresa: {appl_str}\n"
        insights += f"     Data: {date}\n\n"

if patents_china:
    insights += "ğŸ”¥ TOP PATENTS CHINA:\n\n"
    for title, applicant, date, ipc_class in patents_china[:5]:
        appl_str = applicant if applicant else 'N/A'
        insights += f"   â€¢ {title}\n"
        insights += f"     Empresa: {appl_str}\n"
        insights += f"     Data: {date}\n\n"

insights += "\nğŸ’° FUNDING ROUNDS\n"
insights += "-------------------------------------------------------------------\n\n"

if funding:
    insights += "ğŸ”¥ TOP RODADAS:\n\n"
    for company, sector, amount, val, round_type, date in funding[:10]:
        amount_b = amount / 1_000_000_000 if amount else 0
        val_b = val / 1_000_000_000 if val else 0
        insights += f"   â€¢ {company} ({sector})\n"
        insights += f"     {round_type} - ${amount_b:.1f}B"
        if val:
            insights += f" | Valuation: ${val_b:.1f}B"
        insights += f"\n     Data: {date}\n\n"

insights += "\nğŸ“ˆ MERCADO B3 (Brasil)\n"
insights += "-------------------------------------------------------------------\n\n"

if b3:
    insights += "ğŸ”¥ TOP AÃ‡Ã•ES:\n\n"
    for ticker, company, price, change, sector in b3[:10]:
        symbol = "ğŸ“ˆ" if change > 0 else "ğŸ“‰"
        sector_str = sector or 'N/A'
        insights += f"   {symbol} {ticker:8s} | {company:25s} | {change:+6.2f}% | {sector_str}\n"

insights += "\n\nğŸŒ ANÃLISE GEO-LOCALIZADA\n"
insights += "-------------------------------------------------------------------\n\n"

# AnÃ¡lise de Papers por Continente/PaÃ­s/Universidade
if papers:
    insights += "ğŸ“š PESQUISA ACADÃŠMICA POR REGIÃƒO:\n\n"

    countries_found = []
    universities_found = defaultdict(int)
    continents_found = []

    for arxiv_id, title, authors, cats, pub_date, abstract in papers:
        authors_str = ', '.join(authors) if authors else ''
        country, uni = extract_country_from_text(authors_str)

        if country:
            countries_found.append(country)
            continents_found.append(get_continent(country))

        if uni:
            universities_found[uni] += 1

    if continents_found:
        continent_counts = Counter(continents_found)
        insights += "   ğŸ—ºï¸  Papers por Continente:\n"
        for cont, count in continent_counts.most_common(5):
            pct = (count / len(papers)) * 100
            insights += f"      {cont}: {count} papers ({pct:.1f}%)\n"
        insights += "\n"

    if countries_found:
        country_counts = Counter(countries_found)
        insights += "   ğŸŒ Top PaÃ­ses em Pesquisa:\n"
        for country, count in country_counts.most_common(5):
            insights += f"      {country}: {count} papers\n"
        insights += "\n"

    if universities_found:
        insights += "   ğŸ“ Universidades Mais Ativas:\n"
        for uni, count in sorted(universities_found.items(), key=lambda x: x[1], reverse=True)[:5]:
            specs = UNIVERSITIES.get(uni, (None, []))[1]
            specs_str = ", ".join(specs[:2]) if specs else "Geral"
            insights += f"      â€¢ {uni}: {count} papers (Especialidade: {specs_str})\n"
        insights += "\n"

# AnÃ¡lise de Empresas de IA por Continente/PaÃ­s
if companies:
    insights += "ğŸš€ EMPRESAS DE IA POR REGIÃƒO:\n\n"

    companies_by_continent = defaultdict(list)
    companies_by_country = defaultdict(list)

    for name, country, category, comp_funding, employees, year in companies:
        if country:
            continent = get_continent(country)
            companies_by_continent[continent].append((name, country, comp_funding))
            companies_by_country[country].append((name, category, comp_funding))

    if companies_by_continent:
        insights += "   ğŸ—ºï¸  Por Continente:\n"
        for cont, comps in sorted(companies_by_continent.items(), key=lambda x: len(x[1]), reverse=True)[:5]:
            total_funding = sum(c[2] if c[2] else 0 for c in comps)
            total_funding_b = total_funding / 1_000_000_000
            insights += f"      {cont}: {len(comps)} empresas (${total_funding_b:.1f}B funding total)\n"
        insights += "\n"

    if companies_by_country:
        insights += "   ğŸŒ Top 5 PaÃ­ses:\n"
        for country, comps in sorted(companies_by_country.items(), key=lambda x: len(x[1]), reverse=True)[:5]:
            total_funding = sum(c[2] if c[2] else 0 for c in comps)
            total_funding_b = total_funding / 1_000_000_000
            insights += f"      â€¢ {country}: {len(comps)} empresas (${total_funding_b:.1f}B)\n"

            # Mostrar especializaÃ§Ã£o regional
            if country in REGIONAL_SPECIALIZATIONS:
                specs = REGIONAL_SPECIALIZATIONS[country]
                insights += f"        EspecializaÃ§Ã£o: {', '.join(specs)}\n"
        insights += "\n"

# AnÃ¡lise de Funding por RegiÃ£o
if funding:
    insights += "ğŸ’° INVESTIMENTOS POR REGIÃƒO:\n\n"

    # Agrupar funding por paÃ­s (extrair do nome da empresa ou setor)
    funding_by_continent = defaultdict(lambda: {'deals': 0, 'total': 0})

    for company, sector, amount, val, round_type, date in funding:
        # Tentar extrair paÃ­s do nome da empresa
        country, _ = extract_country_from_text(company)

        if country:
            continent = get_continent(country)
            funding_by_continent[continent]['deals'] += 1
            funding_by_continent[continent]['total'] += amount if amount else 0

    if funding_by_continent:
        insights += "   ğŸ—ºï¸  Por Continente:\n"
        for cont, data in sorted(funding_by_continent.items(), key=lambda x: x[1]['total'], reverse=True):
            amount_b = data['total'] / 1_000_000_000
            deals = data['deals']
            insights += f"      {cont}: ${amount_b:.2f}B em {deals} deals\n"
        insights += "\n"

insights += "\nğŸ”¥ ANÃLISE ESTRATÃ‰GICA (INTELIGÃŠNCIA DE MERCADO)\n"
insights += "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n"

# ============================================================================
# INSIGHT #1: PADRÃ•ES INVISÃVEIS NOS PAPERS (CORRELAÃ‡ÃƒO PESQUISA â†’ PRODUTO)
# ============================================================================
insights += "ğŸ§  INSIGHT #1: O QUE OS PAPERS REVELAM SOBRE O FUTURO\n\n"

if papers:
    # Analisar temas recorrentes
    llm_papers = sum(1 for _, title, _, cats, _, _ in papers if any('language model' in title.lower() or 'llm' in title.lower() or 'gpt' in title.lower()))
    vision_papers = sum(1 for _, _, _, cats, _, _ in papers if cats and any('CV' in c for c in cats))
    robot_papers = sum(1 for _, _, _, cats, _, _ in papers if cats and any('RO' in c for c in cats))
    multimodal_papers = sum(1 for _, title, _, _, _, _ in papers if 'multimodal' in title.lower() or 'vision' in title.lower() and 'language' in title.lower())

    insights += f"   ğŸ“Š DADOS:\n"
    insights += f"      â€¢ Papers sobre LLMs/Scaling: {llm_papers}\n"
    insights += f"      â€¢ Papers sobre VisÃ£o: {vision_papers}\n"
    insights += f"      â€¢ Papers sobre RobÃ³tica: {robot_papers}\n"
    insights += f"      â€¢ Papers Multimodais: {multimodal_papers}\n\n"

    # ANÃLISE CORRELACIONADA
    insights += "   ğŸ’¡ LEITURA:\n"

    if llm_papers > 0:
        insights += "      â†’ Papers sobre scaling laws + efficient attention indicam que o foco mudou:\n"
        insights += "        NÃ£o Ã© mais 'fazer maior', Ã© 'fazer utilizÃ¡vel' (contexto longo, multi-sinal).\n"
        insights += "        Isso Ã© sinal de MATURIDADE, nÃ£o hype.\n\n"

    if multimodal_papers >= 2:
        insights += "      â†’ ExplosÃ£o de papers multimodais (visÃ£o + linguagem + Ã¡udio).\n"
        insights += "        OpenAI/Google/Meta estÃ£o preparando modelos 'tudo-em-um'.\n"
        insights += "        ğŸ“… PREVISÃƒO: GPT-5 ou Gemini 2.0 serÃ¡ multimodal nativo (Q1 2025).\n\n"

    if robot_papers > 0:
        insights += f"      â†’ {robot_papers} papers de robÃ³tica (sim-to-real, manipulaÃ§Ã£o).\n"
        # Correlacionar com funding
        defense_funding = sum(amount for company, sector, amount, _, _, _ in funding if 'defense' in sector.lower() or 'military' in sector.lower()) if funding else 0
        if defense_funding > 1_000_000_000:
            insights += f"        CORRELAÃ‡ÃƒO: ${defense_funding/1e9:.1f}B em funding de Defense AI no mesmo mÃªs.\n"
            insights += "        â†’ Stanford/MIT publicam robÃ³tica â†’ VCs injetam capital em defesa.\n"
            insights += "        ğŸ¯ MOVIMENTO: Humanoides militares/drones autÃ´nomos sÃ£o a prÃ³xima onda.\n\n"

# ============================================================================
# INSIGHT #2: PATENTES = MAPA DO FUTURO (GEOPOLÃTICA TECNOLÃ“GICA)
# ============================================================================
insights += "\nğŸŒ INSIGHT #2: PATENTES REVELAM PRIORIDADES GEOPOLÃTICAS\n\n"

if patents_epo or patents_china:
    insights += "   ğŸ“Š DADOS:\n"
    insights += f"      â€¢ Europa (EPO): {len(patents_epo)} patents\n"
    insights += f"      â€¢ China (WIPO): {len(patents_china)} patents\n\n"

    # AnÃ¡lise de temas (Europa)
    europa_energia = sum(1 for title, _, _, _ in patents_epo if any(word in title.lower() for word in ['hydrogen', 'wind', 'carbon', 'polymer', 'battery']))
    europa_auto = sum(1 for title, _, _, _ in patents_epo if 'automotive' in title.lower() or 'driving' in title.lower())

    # AnÃ¡lise de temas (China)
    china_telecom = sum(1 for title, _, _, _ in patents_china if any(word in title.lower() for word in ['5g', '6g', 'mimo', 'antenna', 'network']))
    china_bio = sum(1 for title, _, _, _ in patents_china if 'crispr' in title.lower() or 'gene' in title.lower())
    china_ai = sum(1 for title, _, _, _ in patents_china if 'nlp' in title.lower() or 'language' in title.lower() or 'autonomous' in title.lower())

    insights += "   ğŸ’¡ LEITURA GEOPOLÃTICA:\n\n"

    if europa_energia >= 3:
        insights += f"      ğŸ‡ªğŸ‡º EUROPA:\n"
        insights += f"         â€¢ {europa_energia}/{len(patents_epo)} patents = energia limpa/materiais avanÃ§ados\n"
        insights += "         â†’ Europa dobrou aposta em REINDUSTRIALIZAÃ‡ÃƒO VERDE.\n"
        insights += "         â†’ Foco: hidrogÃªnio, eÃ³lica, baterias, polÃ­meros sustentÃ¡veis.\n\n"

        # Correlacionar com empresas
        europa_ai_companies = len([c for c in companies if c[1] in ['Germany', 'France', 'UK', 'Switzerland']])
        if europa_ai_companies < 5:
            insights += "         âš ï¸  ANOMALIA: Europa forte em patents, FRACA em empresas de IA.\n"
            insights += "            â†’ VALE DA MORTE EUROPEU: pesquisa nÃ£o vira produto.\n"
            insights += "            ğŸ¯ OPORTUNIDADE: Licenciar patents europeus baratos e comercializar nos USA.\n\n"

    if china_telecom >= 3 or china_ai >= 2:
        insights += f"      ğŸ‡¨ğŸ‡³ CHINA:\n"
        insights += f"         â€¢ {china_telecom}/{len(patents_china)} patents = telecom/5G/6G/sensores\n"
        insights += f"         â€¢ {china_ai}/{len(patents_china)} patents = IA/autonomous systems\n"
        insights += "         â†’ China patenteia INFRAESTRUTURA (hardware, redes, sensores).\n"
        insights += "         â†’ Enquanto USA foca em software/LLMs, China constrÃ³i a base fÃ­sica.\n\n"

        # Correlacionar com empresas China
        china_funding = sum(c[3] if c[3] else 0 for c in companies if c[1] == 'China')
        if china_funding > 5_000_000_000:
            insights += f"         ğŸ’° CORRELAÃ‡ÃƒO: ${china_funding/1e9:.1f}B em empresas chinesas de IA.\n"
            insights += "            â†’ China estÃ¡ ARMANDO algo: patents de infra + capital em IA.\n"
            insights += "            ğŸ“… PREVISÃƒO: Salto chinÃªs em hardware AI entre 2026-2027.\n\n"

# ============================================================================
# INSIGHT #3: FUNDING = MAPA DE CALOR DO FUTURO
# ============================================================================
insights += "\nğŸ’° INSIGHT #3: PARA ONDE O DINHEIRO INTELIGENTE ESTÃ INDO\n\n"

if funding:
    # Agrupar por setor
    sector_totals = defaultdict(lambda: {'total': 0, 'deals': [], 'companies': []})
    for company, sector, amount, val, round_type, date in funding:
        sector_totals[sector]['total'] += amount if amount else 0
        sector_totals[sector]['deals'].append((company, amount, round_type))
        sector_totals[sector]['companies'].append(company)

    top_sectors = sorted(sector_totals.items(), key=lambda x: x[1]['total'], reverse=True)[:3]

    insights += "   ğŸ“Š DADOS:\n"
    for sector, data in top_sectors:
        insights += f"      â€¢ {sector}: ${data['total']/1e9:.1f}B em {len(data['deals'])} deals\n"
    insights += "\n"

    # ANÃLISE CORRELACIONADA
    insights += "   ğŸ’¡ LEITURA:\n\n"

    # Detectar concentraÃ§Ã£o absurda
    if len(top_sectors) > 0:
        top_sector_name = top_sectors[0][0]
        top_sector_total = top_sectors[0][1]['total']

        # Mega-rounds
        mega_rounds = [d for d in top_sectors[0][1]['deals'] if d[1] and d[1] > 1_000_000_000]

        if len(mega_rounds) > 0:
            insights += f"      ğŸ”¥ CONCENTRAÃ‡ÃƒO BRUTAL: {top_sector_name} com ${top_sector_total/1e9:.1f}B.\n"
            insights += f"         â†’ {len(mega_rounds)} mega-rounds (>$1B cada).\n"
            insights += "         â†’ Capital institucional ABANDONOU middle-market.\n"
            insights += "         â†’ Ou vocÃª levanta $1B+, ou nÃ£o existe.\n\n"

            insights += "      âš ï¸  ALERTA: Middle-market de IA MORREU.\n"
            insights += "         â†’ Seed/Series A normais nÃ£o conseguem mais competir.\n"
            insights += "         â†’ VCs estÃ£o fazendo late-stage gigante ou nada.\n\n"

    # Detectar movimentos setoriais
    defense_total = sum(data['total'] for sector, data in sector_totals.items() if 'defense' in sector.lower() or 'military' in sector.lower())
    ai_total = sum(data['total'] for sector, data in sector_totals.items() if 'ai' in sector.lower() or 'artificial' in sector.lower())

    if defense_total > 1_000_000_000:
        insights += f"      ğŸ–ï¸  MOVIMENTO SILENCIOSO: ${defense_total/1e9:.1f}B em Defense AI/Drones.\n"
        insights += "         â†’ Imprensa tech nÃ£o cobriu (foco em LLMs).\n"
        insights += "         â†’ Mas capital institucional rotacionou PESADO para defesa.\n"
        insights += "         â†’ Contexto: TensÃ£o geopolÃ­tica (Taiwan, UcrÃ¢nia, Oriente MÃ©dio).\n"
        insights += "         ğŸ¯ TESE: PrÃ³ximos unicÃ³rnios virÃ£o de defense tech, nÃ£o SaaS.\n\n"

# ============================================================================
# INSIGHT #4: MERCADO B3 + MACRO
# ============================================================================
insights += "\nğŸ“ˆ INSIGHT #4: O QUE O MERCADO BRASILEIRO ESTÃ SINALIZANDO\n\n"

if b3 and len(b3) > 0:
    positive = [s for s in b3 if s[3] > 0]
    negative = [s for s in b3 if s[3] < 0]

    insights += "   ğŸ“Š DADOS:\n"
    insights += f"      â€¢ {len(positive)} aÃ§Ãµes em alta | {len(negative)} em queda\n"

    # Analisar setores em alta
    if positive:
        sectors_up = defaultdict(list)
        for ticker, company, price, change, sector in positive:
            if sector:
                sectors_up[sector].append((ticker, change))

        top_sector_up = max(sectors_up.items(), key=lambda x: len(x[1])) if sectors_up else None

        if top_sector_up:
            insights += f"      â€¢ Setor dominante: {top_sector_up[0]} ({len(top_sector_up[1])} aÃ§Ãµes)\n"

    insights += "\n   ğŸ’¡ LEITURA MACRO:\n\n"

    # Detectar rotaÃ§Ã£o defensiva
    defensivos = sum(1 for _, _, _, _, sector in positive if sector and any(word in sector.lower() for word in ['industrial', 'energia', 'mineraÃ§Ã£o']))
    tech_consumo = sum(1 for _, _, _, _, sector in positive if sector and any(word in sector.lower() for word in ['tecnologia', 'consumo', 'varejo']))

    if defensivos > tech_consumo:
        insights += "      ğŸ›¡ï¸  ROTAÃ‡ÃƒO DEFENSIVA DETECTADA:\n"
        insights += f"         â†’ {defensivos} defensivos em alta vs {tech_consumo} growth/consumo.\n"
        insights += "         â†’ Mercado estÃ¡ buscando: exportadores + value + commodities.\n\n"

        insights += "      ğŸ“‰ CONTEXTO MACRO (inferÃªncia):\n"
        insights += "         â†’ Expectativa: juros altos por mais tempo (Copom cauteloso).\n"
        insights += "         â†’ DÃ³lar volÃ¡til â†’ favorece exportadores (PETR, VALE, WEG).\n"
        insights += "         â†’ Fluxo estrangeiro fugindo de small caps/tech BR.\n\n"

        insights += "      â° MARKET TIMING:\n"
        insights += "         âŒ NÃƒO Ã© momento para: IPOs tech, captaÃ§Ãµes growth, M&A agressivo.\n"
        insights += "         âœ… Ã‰ momento para: Consolidar posiÃ§Ãµes, esperar Fed pivotar.\n\n"

# ============================================================================
# INSIGHT #5: GEOPOLÃTICA TECNOLÃ“GICA (PESQUISA vs COMERCIALIZAÃ‡ÃƒO)
# ============================================================================
insights += "\nğŸŒ INSIGHT #5: O MAPA GEOPOLÃTICO DA INOVAÃ‡ÃƒO\n\n"

if companies and papers:
    # Contar papers por paÃ­s (aproximado)
    usa_papers = sum(1 for _, _, authors, _, _, _ in papers if authors and any('USA' in str(a) or 'US' in str(a) or 'Stanford' in str(a) or 'MIT' in str(a) or 'Berkeley' in str(a) for a in authors))

    # Contar empresas
    usa_companies = [c for c in companies if c[1] == 'USA']
    china_companies = [c for c in companies if c[1] == 'China']
    europa_companies = [c for c in companies if c[1] in ['Germany', 'France', 'UK', 'Switzerland', 'Sweden', 'Netherlands']]
    brasil_companies = [c for c in companies if c[1] in ['Brazil', 'Brasil', 'BR']]

    usa_funding = sum(c[3] if c[3] else 0 for c in usa_companies)
    china_funding = sum(c[3] if c[3] else 0 for c in china_companies)

    insights += "   ğŸ“Š DIVISÃƒO GLOBAL:\n\n"
    insights += f"      ğŸ‡ºğŸ‡¸ USA:\n"
    insights += f"         â€¢ {len(usa_companies)} empresas | ${usa_funding/1e9:.1f}B funding\n"
    insights += f"         â€¢ {usa_papers} papers acadÃªmicos\n"
    insights += f"         â€¢ EspecializaÃ§Ã£o: SOFTWARE (LLMs, aplicaÃ§Ãµes, APIs)\n\n"

    insights += f"      ğŸ‡¨ğŸ‡³ China:\n"
    insights += f"         â€¢ {len(china_companies)} empresas | ${china_funding/1e9:.1f}B funding\n"
    insights += f"         â€¢ {len(patents_china)} patents (telecom, sensores, hardware)\n"
    insights += f"         â€¢ EspecializaÃ§Ã£o: HARDWARE (chips, infraestrutura, 5G)\n\n"

    if len(patents_epo) > 5:
        insights += f"      ğŸ‡ªğŸ‡º Europa:\n"
        insights += f"         â€¢ {len(europa_companies)} empresas de IA\n"
        insights += f"         â€¢ {len(patents_epo)} patents (energia, materiais, auto)\n"
        insights += f"         â€¢ EspecializaÃ§Ã£o: ENERGIA/SUSTENTABILIDADE\n"
        insights += "         âš ï¸  PROBLEMA: Pesquisa forte, comercializaÃ§Ã£o fraca (vale da morte).\n\n"

    insights += f"      ğŸ‡§ğŸ‡· Brasil:\n"
    insights += f"         â€¢ {len(brasil_companies)} empresas com funding relevante\n"
    insights += "         â€¢ EspecializaÃ§Ã£o: ESPECTADOR (consumidor, nÃ£o produtor)\n\n"

    insights += "   ğŸ’¡ CONCLUSÃƒO GEOPOLÃTICA:\n\n"
    insights += "      O eixo tecnolÃ³gico do planeta se formalizou:\n"
    insights += "         â€¢ USA controla SOFTWARE (modelos, APIs, produtos)\n"
    insights += "         â€¢ China controla HARDWARE (chips, infra, manufatura)\n"
    insights += "         â€¢ Europa controla ENERGIA (transiÃ§Ã£o verde)\n"
    insights += "         â€¢ Brasil = consumidor final.\n\n"

    insights += "      ğŸ¯ IMPLICAÃ‡ÃƒO ESTRATÃ‰GICA:\n"
    insights += "         â†’ Quem controla COMPUTE controla IA.\n"
    insights += "         â†’ Quem controla IA controla DEFESA.\n"
    insights += "         â†’ NVDA/TSMC/AMD sÃ£o o novo petrÃ³leo.\n"
    insights += "         â†’ Brasil precisa URGENTEMENTE de compute soberano ou ficarÃ¡ refÃ©m.\n\n"

insights += """

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Gerado por Sofia Pulse v4.0 - Dados reais dos collectors
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# Salvar
with open('analytics/premium-insights/latest-v4.txt', 'w', encoding='utf-8') as f:
    f.write(insights)

with open('analytics/premium-insights/latest-v4.md', 'w', encoding='utf-8') as f:
    f.write(insights)

# TambÃ©m como latest-geo para compatibilidade com email
with open('analytics/premium-insights/latest-geo.txt', 'w', encoding='utf-8') as f:
    f.write(insights)

with open('analytics/premium-insights/latest-geo.md', 'w', encoding='utf-8') as f:
    f.write(insights)

print("âœ… Insights v4.0 gerados!")
print(f"ğŸ“„ analytics/premium-insights/latest-v4.txt")
print(f"\nPreview:\n{insights[:800]}...\n")

# Export CSVs
print("ğŸ“¤ Exportando CSVs...")

# Papers CSV
cur.execute("""
    SELECT arxiv_id, title, authors, categories, published_date
    FROM arxiv_ai_papers
    ORDER BY published_date DESC
    LIMIT 100
""")
with open('analytics/premium-insights/arxiv_papers.csv', 'w', encoding='utf-8') as f:
    f.write("arxiv_id,title,authors,categories,published_date\n")
    for row in cur.fetchall():
        # Simplificar arrays para CSV
        arxiv_id, title, authors, cats, date = row
        authors_str = ';'.join(authors) if authors else ''
        cats_str = ';'.join(cats) if cats else ''
        f.write(f'"{arxiv_id}","{title}","{authors_str}","{cats_str}","{date}"\n')

# Companies CSV
cur.execute("""
    SELECT name, country, category, total_funding_usd, employee_count, founded_year
    FROM ai_companies
    ORDER BY total_funding_usd DESC NULLS LAST
""")
with open('analytics/premium-insights/ai_companies.csv', 'w', encoding='utf-8') as f:
    f.write("name,country,category,total_funding_usd,employee_count,founded_year\n")
    for row in cur.fetchall():
        f.write(','.join(str(x) if x is not None else '' for x in row) + '\n')

print("âœ… CSVs exportados!")
print("   - arxiv_papers.csv")
print("   - ai_companies.csv")

conn.close()

print("\nğŸ‰ CONCLUÃDO! Agora COM papers, patents, startups e tudo mais!")
