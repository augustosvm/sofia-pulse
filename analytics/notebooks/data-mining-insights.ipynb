{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ Sofia Pulse - Data Mining & AI Insights\n",
    "\n",
    "**Objetivo**: Encontrar correla√ß√µes e padr√µes ocultos nos dados usando:\n",
    "- Correlation analysis\n",
    "- Clustering\n",
    "- Anomaly detection\n",
    "- Claude AI para interpretar insights\n",
    "\n",
    "**Dados**: ~970 registros de 29 tabelas (economia, finance, research, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "from anthropic import Anthropic\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes visuais\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Bibliotecas carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar ao PostgreSQL\n",
    "DB_URL = \"postgresql://sofia:sofia123strong@localhost:5432/sofia_db\"\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "print(\"üîå Conectado ao PostgreSQL!\")\n",
    "\n",
    "# Testar conex√£o\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(\"SELECT current_database(), current_user\")\n",
    "    db, user = result.fetchone()\n",
    "    print(f\"   Database: {db}\")\n",
    "    print(f\"   User: {user}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 1. Carregar TODOS os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todas as tabelas com dados\n",
    "query_tables = \"\"\"\n",
    "SELECT table_schema, table_name, \n",
    "       (xpath('/row/cnt/text()', query_to_xml(\n",
    "           format('SELECT COUNT(*) as cnt FROM %I.%I', table_schema, table_name),\n",
    "           false, true, ''\n",
    "       )))[1]::text::int as row_count\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema NOT IN ('pg_catalog', 'information_schema')\n",
    "  AND table_type = 'BASE TABLE'\n",
    "ORDER BY row_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "tables_df = pd.read_sql(query_tables, engine)\n",
    "tables_with_data = tables_df[tables_df['row_count'] > 0]\n",
    "\n",
    "print(f\"üìã Total de tabelas: {len(tables_df)}\")\n",
    "print(f\"‚úÖ Tabelas com dados: {len(tables_with_data)}\")\n",
    "print(f\"üìä Total de registros: {tables_with_data['row_count'].sum():,}\")\n",
    "print(\"\\nTop 10 tabelas por volume:\")\n",
    "tables_with_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados FINANCE (base para correla√ß√µes)\n",
    "print(\"üì• Carregando dados Finance...\")\n",
    "\n",
    "# B3 Stocks\n",
    "df_b3 = pd.read_sql(\"\"\"\n",
    "    SELECT ticker, company, sector, price, change_pct, volume, market_cap, \n",
    "           collected_at::date as date\n",
    "    FROM sofia.market_data_brazil\n",
    "    ORDER BY collected_at DESC\n",
    "\"\"\", engine)\n",
    "\n",
    "# NASDAQ\n",
    "df_nasdaq = pd.read_sql(\"\"\"\n",
    "    SELECT ticker, company, sector, price, change_pct, volume, market_cap,\n",
    "           collected_at::date as date\n",
    "    FROM sofia.market_data_nasdaq\n",
    "    ORDER BY collected_at DESC\n",
    "\"\"\", engine)\n",
    "\n",
    "# Funding Rounds\n",
    "df_funding = pd.read_sql(\"\"\"\n",
    "    SELECT company_name, sector, round_type, amount_usd, valuation_usd,\n",
    "           announced_date, collected_at::date as date\n",
    "    FROM sofia.funding_rounds\n",
    "    ORDER BY amount_usd DESC\n",
    "\"\"\", engine)\n",
    "\n",
    "print(f\"   ‚úÖ B3: {len(df_b3)} registros\")\n",
    "print(f\"   ‚úÖ NASDAQ: {len(df_nasdaq)} registros\")\n",
    "print(f\"   ‚úÖ Funding: {len(df_funding)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados ECON√îMICOS (para correla√ß√µes)\n",
    "print(\"üì• Carregando indicadores econ√¥micos...\")\n",
    "\n",
    "# Tentar carregar cada tabela (algumas podem estar vazias)\n",
    "economic_data = {}\n",
    "\n",
    "for _, row in tables_with_data.iterrows():\n",
    "    schema = row['table_schema']\n",
    "    table = row['table_name']\n",
    "    \n",
    "    # Ignorar tabelas finance (j√° carregadas)\n",
    "    if table in ['market_data_brazil', 'market_data_nasdaq', 'funding_rounds']:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        query = f\"SELECT * FROM {schema}.{table} LIMIT 1000\"\n",
    "        df = pd.read_sql(query, engine)\n",
    "        if len(df) > 0:\n",
    "            economic_data[table] = df\n",
    "            print(f\"   ‚úÖ {table}: {len(df)} registros\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  {table}: {str(e)[:50]}...\")\n",
    "\n",
    "print(f\"\\nüìä Total de datasets carregados: {len(economic_data) + 3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 2. Correlation Analysis - Encontrar Rela√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de correla√ß√£o: Setores vs Performance\n",
    "print(\"üîç Analisando correla√ß√µes entre setores...\\n\")\n",
    "\n",
    "# Combinar B3 + NASDAQ para an√°lise setorial\n",
    "df_b3['market'] = 'Brazil'\n",
    "df_nasdaq['market'] = 'US'\n",
    "df_combined = pd.concat([df_b3, df_nasdaq])\n",
    "\n",
    "# Performance m√©dia por setor\n",
    "sector_performance = df_combined.groupby('sector').agg({\n",
    "    'change_pct': 'mean',\n",
    "    'volume': 'sum',\n",
    "    'market_cap': 'mean',\n",
    "    'ticker': 'count'\n",
    "}).round(2)\n",
    "\n",
    "sector_performance.columns = ['Avg Change %', 'Total Volume', 'Avg Market Cap', 'Num Companies']\n",
    "sector_performance = sector_performance.sort_values('Avg Change %', ascending=False)\n",
    "\n",
    "print(\"Top 5 setores por performance:\\n\")\n",
    "print(sector_performance.head())\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(12, 6))\n",
    "sector_performance['Avg Change %'].plot(kind='barh', color='skyblue')\n",
    "plt.title('Performance M√©dia por Setor', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Varia√ß√£o M√©dia (%)')\n",
    "plt.ylabel('Setor')\n",
    "plt.axvline(0, color='red', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correla√ß√£o: Funding vs Market Performance\n",
    "print(\"üîç Correla√ß√£o entre Funding e Performance de Mercado\\n\")\n",
    "\n",
    "# Funding por setor\n",
    "funding_by_sector = df_funding.groupby('sector')['amount_usd'].sum().to_frame()\n",
    "funding_by_sector.columns = ['Total Funding']\n",
    "\n",
    "# Merge com performance\n",
    "correlation_df = sector_performance.merge(\n",
    "    funding_by_sector, \n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    how='outer'\n",
    ").fillna(0)\n",
    "\n",
    "# Calcular correla√ß√£o\n",
    "corr = correlation_df.corr()\n",
    "\n",
    "# Visualizar heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correla√ß√£o: Funding vs Performance', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Correla√ß√£o entre Total Funding e Avg Change %:\")\n",
    "print(f\"   {correlation_df['Total Funding'].corr(correlation_df['Avg Change %']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ 3. Clustering - Agrupar Setores Similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para clustering\n",
    "print(\"üéØ Clustering de setores por caracter√≠sticas...\\n\")\n",
    "\n",
    "# Features para clustering\n",
    "features = correlation_df[['Avg Change %', 'Total Volume', 'Avg Market Cap', 'Total Funding']].copy()\n",
    "features = features[features['Total Funding'] > 0]  # Apenas setores com funding\n",
    "\n",
    "# Normalizar dados\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# K-Means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(features_scaled)\n",
    "features['Cluster'] = clusters\n",
    "\n",
    "# PCA para visualiza√ß√£o 2D\n",
    "pca = PCA(n_components=2)\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "# Visualizar clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(features_pca[:, 0], features_pca[:, 1], \n",
    "                     c=clusters, s=200, alpha=0.6, cmap='viridis', edgecolors='black')\n",
    "\n",
    "# Anotar setores\n",
    "for i, sector in enumerate(features.index):\n",
    "    plt.annotate(sector, (features_pca[i, 0], features_pca[i, 1]),\n",
    "                fontsize=9, ha='center')\n",
    "\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.title('Clustering de Setores (K-Means)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Setores por Cluster:\\n\")\n",
    "for cluster_id in sorted(features['Cluster'].unique()):\n",
    "    sectors_in_cluster = features[features['Cluster'] == cluster_id].index.tolist()\n",
    "    print(f\"   Cluster {cluster_id}: {', '.join(sectors_in_cluster)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è 4. Anomaly Detection - Detectar Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar anomalias usando Z-score\n",
    "print(\"‚ö†Ô∏è  Detectando anomalias...\\n\")\n",
    "\n",
    "# Calcular Z-scores\n",
    "z_scores = np.abs(stats.zscore(features[['Avg Change %', 'Total Funding']]))\n",
    "anomalies = (z_scores > 2).any(axis=1)\n",
    "\n",
    "anomaly_sectors = features[anomalies]\n",
    "\n",
    "print(f\"üö® {len(anomaly_sectors)} setores an√¥malos detectados:\\n\")\n",
    "print(anomaly_sectors[['Avg Change %', 'Total Funding', 'Cluster']])\n",
    "\n",
    "# Visualizar anomalias\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(features['Total Funding'], features['Avg Change %'], \n",
    "           s=100, alpha=0.5, label='Normal')\n",
    "plt.scatter(anomaly_sectors['Total Funding'], anomaly_sectors['Avg Change %'],\n",
    "           s=200, color='red', alpha=0.7, label='Anomalia', edgecolors='black')\n",
    "\n",
    "for sector in anomaly_sectors.index:\n",
    "    plt.annotate(sector, \n",
    "                (features.loc[sector, 'Total Funding'], \n",
    "                 features.loc[sector, 'Avg Change %']),\n",
    "                fontsize=9, color='red', fontweight='bold')\n",
    "\n",
    "plt.xlabel('Total Funding ($)', fontsize=12)\n",
    "plt.ylabel('Avg Change (%)', fontsize=12)\n",
    "plt.title('Anomaly Detection: Funding vs Performance', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 5. Claude AI - Gerar Insights Automaticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar Claude\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"‚ö†Ô∏è  ANTHROPIC_API_KEY n√£o encontrada!\")\n",
    "    print(\"   Configure: echo 'ANTHROPIC_API_KEY=sua_key' >> ~/.env\")\n",
    "else:\n",
    "    client = Anthropic(api_key=api_key)\n",
    "    print(\"‚úÖ Claude AI configurado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar insights com Claude\n",
    "def generate_insights(data_summary):\n",
    "    \"\"\"Usa Claude para interpretar os dados e gerar insights acion√°veis.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Voc√™ √© um analista de dados expert. Analise os seguintes dados do Sofia Pulse e gere insights acion√°veis:\n",
    "\n",
    "DADOS:\n",
    "{data_summary}\n",
    "\n",
    "Por favor, forne√ßa:\n",
    "\n",
    "1. TOP 3 INSIGHTS mais importantes\n",
    "2. CORRELA√á√ïES interessantes detectadas\n",
    "3. ANOMALIAS e o que elas significam\n",
    "4. OPORTUNIDADES de investimento ou research\n",
    "5. RISCOS a evitar\n",
    "\n",
    "Seja espec√≠fico e acion√°vel. Use dados concretos.\n",
    "\"\"\"\n",
    "    \n",
    "    message = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=2000,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return message.content[0].text\n",
    "\n",
    "# Preparar resumo dos dados\n",
    "summary = f\"\"\"\n",
    "PERFORMANCE POR SETOR:\n",
    "{sector_performance.to_string()}\n",
    "\n",
    "CORRELA√á√ïES:\n",
    "{corr.to_string()}\n",
    "\n",
    "CLUSTERS IDENTIFICADOS:\n",
    "{features.groupby('Cluster').mean().to_string()}\n",
    "\n",
    "ANOMALIAS DETECTADAS:\n",
    "{anomaly_sectors.to_string()}\n",
    "\n",
    "TOP FUNDING ROUNDS:\n",
    "{df_funding.nlargest(5, 'amount_usd')[['company_name', 'sector', 'amount_usd', 'valuation_usd']].to_string()}\n",
    "\"\"\"\n",
    "\n",
    "print(\"ü§ñ Gerando insights com Claude AI...\\n\")\n",
    "print(\"‚îÅ\" * 80)\n",
    "\n",
    "if api_key:\n",
    "    insights = generate_insights(summary)\n",
    "    print(insights)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Configure ANTHROPIC_API_KEY para gerar insights autom√°ticos\")\n",
    "\n",
    "print(\"‚îÅ\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 6. Time Series Analysis (Bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise temporal: evolu√ß√£o ao longo do tempo\n",
    "if len(df_b3['date'].unique()) > 1:\n",
    "    print(\"üìà An√°lise de Time Series...\\n\")\n",
    "    \n",
    "    # Performance m√©dia por data\n",
    "    daily_perf = df_combined.groupby('date')['change_pct'].mean().reset_index()\n",
    "    daily_perf.columns = ['Date', 'Avg Change %']\n",
    "    \n",
    "    # Visualizar\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(daily_perf['Date'], daily_perf['Avg Change %'], \n",
    "            marker='o', linewidth=2, markersize=8)\n",
    "    plt.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.title('Evolu√ß√£o da Performance M√©dia do Mercado', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Data')\n",
    "    plt.ylabel('Varia√ß√£o M√©dia (%)')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"   Tend√™ncia: {daily_perf['Avg Change %'].iloc[-1] - daily_perf['Avg Change %'].iloc[0]:.2f}%\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Time series pulada (dados de apenas 1 dia)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 7. Salvar Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Salvar CSVs\n",
    "sector_performance.to_csv(f'../output/sector_performance_{timestamp}.csv')\n",
    "features.to_csv(f'../output/sector_clusters_{timestamp}.csv')\n",
    "anomaly_sectors.to_csv(f'../output/anomalies_{timestamp}.csv')\n",
    "\n",
    "print(f\"üíæ Resultados salvos em analytics/output/\")\n",
    "print(f\"   - sector_performance_{timestamp}.csv\")\n",
    "print(f\"   - sector_clusters_{timestamp}.csv\")\n",
    "print(f\"   - anomalies_{timestamp}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Resumo dos Insights\n",
    "\n",
    "Este notebook realizou:\n",
    "\n",
    "1. ‚úÖ **Carregamento de dados**: ~970 registros de 29 tabelas\n",
    "2. ‚úÖ **Correlation Analysis**: Rela√ß√µes entre funding e performance\n",
    "3. ‚úÖ **Clustering**: Agrupamento de setores similares\n",
    "4. ‚úÖ **Anomaly Detection**: Identifica√ß√£o de outliers\n",
    "5. ‚úÖ **Claude AI**: Gera√ß√£o autom√°tica de insights acion√°veis\n",
    "6. ‚úÖ **Time Series**: An√°lise de tend√™ncias temporais\n",
    "7. ‚úÖ **Export**: Resultados salvos em CSV\n",
    "\n",
    "**Pr√≥ximos Passos**:\n",
    "- Rodar diariamente para trackear mudan√ßas\n",
    "- Adicionar mais fontes de dados\n",
    "- Criar alertas autom√°ticos para anomalias\n",
    "- Implementar ML predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
