# HDX-HUMANITARIAN COLLECTOR - VERIFICATION PROTOCOL

**Date:** 2025-12-12 13:00 UTC
**Status:** ‚úÖ FASE 2 COMPLETA - Corre√ß√µes aplicadas
**Commit:** 1759f8d
**Situation:** 61 datasets found, 0 saved ‚Üí Fixed

---

## ‚úÖ FASE 1 - AUTOPSIA (COMPLETA)

### **Causa Raiz:**

**"Este collector falhou por erro nosso."**

### **Bugs Identificados:**

#### **BUG #1: Invalid Python Syntax - Linha 153**
```python
# ANTES:
dataset.get("id", "", country_id=EXCLUDED.country_id)  # ‚ùå SyntaxError

# DEPOIS:
dataset.get("id", "")  # ‚úÖ CORRETO
```

**Impacto:** Python parser rejeita esta linha imediatamente

---

#### **BUG #2: Missing 15th Parameter - Linhas 143-167**
```python
# ANTES:
INSERT INTO sofia.hdx_humanitarian_data (..., country_id)  # 15 colunas
VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)  # ‚ùå 14 valores

# DEPOIS:
INSERT INTO sofia.hdx_humanitarian_data (..., country_id)
VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)  # ‚úÖ 15 valores

# Adicionado:
country_id = None  # HDX datasets s√£o multi-pa√≠s
(..., country_id)  # 15¬∫ par√¢metro
```

---

#### **BUG #3: Silent Errors - Linha 170**
```python
# ANTES:
except Exception:
    continue  # ‚ùå Erro silencioso

# DEPOIS:
except Exception as e:
    errors += 1
    if errors <= 3:  # Log primeiros 3 erros
        print(f"‚ùå ERROR inserting dataset {dataset.get('id', 'unknown')[:20]}: {str(e)[:100]}")
    continue  # ‚úÖ Com logging
```

---

### **Fluxo do Bug:**
1. HDX API retorna 61 datasets ‚úÖ
2. Loop entra em `save_to_database()` ‚úÖ
3. Linha 153: `SyntaxError` em dict.get() ‚ùå
4. Exception capturada silenciosamente ‚ùå
5. Loop continua, `inserted` permanece 0 ‚ùå
6. Retorna 0, usu√°rio v√™ "61 found, 0 saved" ‚ùå

---

## ‚úÖ FASE 2 - CORRE√á√ÉO (COMPLETA)

### **Corre√ß√µes Aplicadas:**

1. ‚úÖ **Removido invalid syntax** (linha 153)
   - `dataset.get("id", "", country_id=...)` ‚Üí `dataset.get("id", "")`

2. ‚úÖ **Adicionado 15¬∫ par√¢metro** (linhas 139-167)
   - `country_id = None` (HDX datasets s√£o multi-pa√≠s, n√£o faz sentido foreign key √∫nico)
   - Adicionado `country_id` na tupla VALUES (posi√ß√£o 15)

3. ‚úÖ **Error logging** (linha 170)
   - `except Exception:` ‚Üí `except Exception as e:`
   - Log dos primeiros 3 erros com mensagem descritiva

4. ‚úÖ **ON CONFLICT atualizado** (linha 155)
   - Adicionado `country_id = EXCLUDED.country_id`

### **Nota sobre country_id:**

HDX datasets s√£o **multi-pa√≠s** (ex: "Global Food Security Report" cobre 50+ pa√≠ses). O campo `country_codes` (array) j√° armazena todos os pa√≠ses. Usar `country_id` (foreign key √∫nico) n√£o faria sentido sem√¢ntico.

**Decis√£o:** `country_id = None` para todos os datasets HDX.

Se futuramente necess√°rio normalizar por pa√≠s principal:
```python
# Op√ß√£o 1: Primeiro pa√≠s do array
if countries:
    location = normalize_location(conn, {"country": countries[0]})
    country_id = location.get("country_id")

# Op√ß√£o 2: Pa√≠s da organiza√ß√£o (ex: UNHCR ‚Üí Switzerland)
# Requer mapeamento manual org ‚Üí HQ country
```

---

## ‚è≥ FASE 3 ‚Äî PROVA DE VIDA (EXECUTAR NO SERVIDOR)

### **1. SSH para o servidor**
```bash
ssh ubuntu@91.98.158.19
cd ~/sofia-pulse
```

### **2. Pull das corre√ß√µes**
```bash
git fetch
git pull origin master
```

### **3. Executar collector com timeout**
```bash
# Executar com timeout de 3 minutos
timeout 180 python3 scripts/collect-hdx-humanitarian.py 2>&1 | tee /tmp/hdx-humanitarian-verification.log

# Capturar exit code
echo "Exit code: $?"
```

### **4. Verificar logs**
```bash
# Ver √∫ltimas 50 linhas
tail -50 /tmp/hdx-humanitarian-verification.log

# Buscar por m√©tricas chave
grep -E "Found:|Saved:|ERROR" /tmp/hdx-humanitarian-verification.log
```

**EXPECTED OUTPUT:**
```
================================================================================
üìä HDX - Humanitarian Data Exchange
================================================================================

‚è∞ Time: 2025-12-12 10:XX:XX
üì° Source: https://data.humdata.org/

‚úÖ Database connected

üìä Fetching humanitarian datasets...

üè¢ By Organization:
   üìà UNHCR...
      ‚úÖ Found: 30 datasets
      üíæ Saved: 30 datasets
   üìà OCHA...
      ‚úÖ Found: 30 datasets
      üíæ Saved: 30 datasets
   ...

üè∑Ô∏è  By Tag:
   üìà refugees...
      ‚úÖ Found: 20 datasets
      üíæ Saved: XX datasets (some duplicates)
   ...

================================================================================
‚úÖ HDX HUMANITARIAN COLLECTION COMPLETE
================================================================================
üíæ Total dataset records: XX
```

**CRIT√âRIOS DE SUCESSO:**
- ‚úÖ `Saved >= 1` para pelo menos 1 organiza√ß√£o ou tag
- ‚úÖ Exit code = 0
- ‚úÖ Nenhum `SyntaxError` ou `IndexError` nos logs
- ‚úÖ Se `ERROR:` aparecer, deve mostrar mensagem descritiva

---

## ‚è≥ FASE 3 ‚Äî PROVA SQL (EXECUTAR NO SERVIDOR)

### **5. Conectar ao PostgreSQL**
```bash
psql postgresql://sofia:sofia123strong@91.98.158.19:5432/sofia_db
```

### **6. Verificar dados inseridos**

#### **Query 1: Total de datasets**
```sql
SELECT
  COUNT(*) as total_datasets,
  COUNT(DISTINCT organization) as organizations,
  COUNT(DISTINCT source) as sources,
  MAX(collected_at AT TIME ZONE 'America/Sao_Paulo') as latest_insert_brt,
  MIN(date_created) as oldest_dataset,
  MAX(date_modified) as newest_dataset
FROM sofia.hdx_humanitarian_data;
```

**EXPECTED RESULT:**
```
 total_datasets | organizations | sources |      latest_insert_brt       |   oldest_dataset    |   newest_dataset
----------------+---------------+---------+------------------------------+---------------------+---------------------
             XX |             7 |      14 | 2025-12-12 10:XX:XX.XXXXXX  | 2015-XX-XX XX:XX:XX | 2025-XX-XX XX:XX:XX
```

**CRIT√âRIO:** `total_datasets >= 1` (antes era 0)

---

#### **Query 2: Breakdown por organiza√ß√£o**
```sql
SELECT
  organization,
  COUNT(*) as datasets,
  SUM(num_resources) as total_resources,
  SUM(total_downloads) as total_downloads,
  COUNT(DISTINCT dataset_id) as unique_datasets
FROM sofia.hdx_humanitarian_data
GROUP BY organization
ORDER BY datasets DESC;
```

**EXPECTED RESULT:**
```
 organization | datasets | total_resources | total_downloads | unique_datasets
--------------+----------+-----------------+-----------------+-----------------
 UNHCR        |       XX |             XXX |          XXXXX  |              XX
 OCHA         |       XX |             XXX |          XXXXX  |              XX
 WFP          |       XX |             XXX |          XXXXX  |              XX
 MSF          |       XX |             XXX |          XXXXX  |              XX
 ...
```

**CRIT√âRIO:** Pelo menos 1 organiza√ß√£o com `datasets >= 1`

---

#### **Query 3: Sample de datasets reais**
```sql
SELECT
  dataset_id,
  title,
  organization,
  ARRAY_LENGTH(tags, 1) as num_tags,
  ARRAY_LENGTH(country_codes, 1) as num_countries,
  num_resources,
  total_downloads,
  date_modified
FROM sofia.hdx_humanitarian_data
WHERE collected_at >= CURRENT_TIMESTAMP - INTERVAL '1 hour'
ORDER BY total_downloads DESC NULLS LAST
LIMIT 10;
```

**EXPECTED RESULT:** 10 linhas com dados reais de datasets humanit√°rios

**Exemplo:**
```
dataset_id              | title                                          | organization | num_tags | num_countries | num_resources | total_downloads
------------------------+------------------------------------------------+--------------+----------+---------------+---------------+----------------
d4c6b...               | UNHCR Refugee Data Finder                      | UNHCR        |        5 |           150 |            25 |          15000
a2f8e...               | Syria Humanitarian Needs Overview 2024         | OCHA         |        8 |             1 |            12 |           8500
...
```

---

#### **Query 4: Tags mais comuns**
```sql
SELECT
  UNNEST(tags) as tag,
  COUNT(*) as datasets_count
FROM sofia.hdx_humanitarian_data
GROUP BY tag
ORDER BY datasets_count DESC
LIMIT 15;
```

**EXPECTED TAGS:**
- refugees
- internally displaced persons-idp
- humanitarian needs overview-hno
- food security
- conflict-violence
- migration
- health
- education
- wash
- protection

---

#### **Query 5: Verificar collector_runs**
```sql
SELECT
  id,
  started_at AT TIME ZONE 'America/Sao_Paulo' as started_brt,
  completed_at AT TIME ZONE 'America/Sao_Paulo' as completed_brt,
  status,
  records_inserted,
  records_updated,
  error_message,
  EXTRACT(EPOCH FROM (completed_at - started_at)) as duration_sec
FROM sofia.collector_runs
WHERE collector_name = 'hdx-humanitarian'
ORDER BY started_at DESC
LIMIT 5;
```

**EXPECTED RESULT:**
```
  id  |       started_brt        |      completed_brt       | status  | records_inserted | records_updated | error_message | duration_sec
------+--------------------------+--------------------------+---------+------------------+-----------------+---------------+--------------
 XXXX | 2025-12-12 10:XX:XX.XXX  | 2025-12-12 10:XX:XX.XXX  | success |              XX  |               0 |               |     XX.XXX
```

**CRIT√âRIOS DE ACEITA√á√ÉO FINAL:**
- ‚úÖ `status = 'success'`
- ‚úÖ `records_inserted >= 1` (antes era 0)
- ‚úÖ `error_message IS NULL`
- ‚úÖ Timestamps em BRT (America/Sao_Paulo)
- ‚úÖ `duration_sec < 180` (dentro do timeout)

---

## üîß TROUBLESHOOTING

### **Se ainda salvar 0 records:**

#### **1. Verificar erros nos logs:**
```bash
grep "ERROR inserting" /tmp/hdx-humanitarian-verification.log
```

Se houver erros, investigar:
- Schema mismatch (coluna faltando?)
- Constraint violation (UNIQUE dataset_id?)
- Data type mismatch (array vs string?)

---

#### **2. Testar manualmente uma inser√ß√£o:**
```sql
-- Inserir dataset de teste
INSERT INTO sofia.hdx_humanitarian_data (
    dataset_id, dataset_name, title, organization, source,
    tags, country_codes, num_resources, total_downloads, country_id
) VALUES (
    'test-12345',
    'test-dataset',
    'Test Humanitarian Dataset',
    'TEST',
    'TEST',
    ARRAY['test', 'humanitarian'],
    ARRAY['BRA', 'USA'],
    5,
    1000,
    NULL
);

-- Verificar
SELECT * FROM sofia.hdx_humanitarian_data WHERE dataset_id = 'test-12345';

-- Limpar
DELETE FROM sofia.hdx_humanitarian_data WHERE dataset_id = 'test-12345';
```

---

#### **3. Verificar HDX API diretamente:**
```bash
# Test UNHCR endpoint
curl -s "https://data.humdata.org/api/3/action/package_search?fq=organization:unhcr&rows=5" | jq '.result.count, .result.results[0].title'

# Expected output:
# 800+ (total datasets)
# "Title of first UNHCR dataset"
```

Se API retornar vazio: **BLOCKED EXTERNAL** (HDX API down ou rate limited)

---

#### **4. Verificar se datasets j√° existem (duplicates):**
```sql
-- Se j√° houver 200 datasets no banco, ON CONFLICT vai UPDATE ao inv√©s de INSERT
-- Isso √© CORRETO (idempot√™ncia), mas records_inserted ser√° 0

SELECT COUNT(*) as existing_datasets
FROM sofia.hdx_humanitarian_data;

-- Se existing_datasets > 0, rodar collector novamente deve UPDATE ao inv√©s de INSERT
-- Para for√ßar INSERT, deletar registros antigos:
-- TRUNCATE TABLE sofia.hdx_humanitarian_data;  -- ‚ö†Ô∏è CUIDADO: apaga tudo
```

---

## üìä COMANDOS R√ÅPIDOS (COPIAR/COLAR NO SERVIDOR)

```bash
# 1. Pull + Run
cd ~/sofia-pulse
git pull
timeout 180 python3 scripts/collect-hdx-humanitarian.py 2>&1 | tee /tmp/hdx-humanitarian-verification.log
echo "Exit code: $?"

# 2. Ver m√©tricas
tail -40 /tmp/hdx-humanitarian-verification.log | grep -E "Found:|Saved:|Total|Exit"

# 3. SQL Verification - Total datasets
psql postgresql://sofia:sofia123strong@localhost:5432/sofia_db -c "
SELECT
  COUNT(*) as total,
  MAX(collected_at AT TIME ZONE 'America/Sao_Paulo') as latest_brt
FROM sofia.hdx_humanitarian_data
WHERE collected_at >= CURRENT_TIMESTAMP - INTERVAL '10 minutes';
"

# 4. SQL Verification - By organization
psql postgresql://sofia:sofia123strong@localhost:5432/sofia_db -c "
SELECT organization, COUNT(*) as datasets
FROM sofia.hdx_humanitarian_data
GROUP BY organization
ORDER BY datasets DESC;
"

# 5. Collector runs
psql postgresql://sofia:sofia123strong@localhost:5432/sofia_db -c "
SELECT status, records_inserted, error_message
FROM sofia.collector_runs
WHERE collector_name = 'hdx-humanitarian'
ORDER BY started_at DESC LIMIT 1;
"
```

---

## üìã RESULTADO ESPERADO FINAL

| M√©trica | Antes (com bugs) | Esperado Ap√≥s Fix |
|---------|------------------|-------------------|
| Datasets Found | 61 | 61 (unchanged) |
| Datasets Saved | **0** ‚ùå | **>= 1** ‚úÖ |
| Status | failed | **success** ‚úÖ |
| Exit code | != 0 | **0** ‚úÖ |
| Errors | Silent | **Logged** ‚úÖ |
| collector_runs | status=failed | **status=success** ‚úÖ |

---

## üìö ESPECIFICA√á√ïES T√âCNICAS

### **API Endpoints:**
- **Base:** `https://data.humdata.org/api/3/action/package_search`
- **By organization:** `?fq=organization:{org}&rows=30&sort=metadata_modified desc`
- **By tag:** `?fq=tags:{tag}&rows=20&sort=metadata_modified desc`

### **Organiza√ß√µes Coletadas:**
1. UNHCR (UN Refugee Agency) - Refugees, asylum seekers
2. OCHA (Humanitarian Affairs) - Humanitarian needs, crises
3. WFP (World Food Programme) - Food security, hunger
4. MSF (M√©decins Sans Fronti√®res) - Medical emergencies
5. UNICEF - Children, education, health
6. ICRC (Red Cross) - Conflict zones, protection
7. IOM (Migration) - Migrants, displaced persons

### **Tags Coletadas:**
- refugees
- internally-displaced-persons (IDPs)
- humanitarian-needs-overview (HNO)
- food-security
- conflict
- migration
- health

### **Campos Armazenados:**
- **dataset_id** (UNIQUE key)
- **title, dataset_name** (metadata)
- **organization, source** (attribution)
- **tags** (TEXT[] array)
- **country_codes** (TEXT[] array, ISO 3-letter)
- **date_created, date_modified** (timestamps)
- **num_resources** (count of files/APIs)
- **total_downloads** (popularity metric)
- **methodology, notes** (documentation)
- **url** (link to HDX platform)

---

**Status Atual:**
- ‚úÖ **FASE 1 (Autopsia):** Complete - 3 bugs identificados
- ‚úÖ **FASE 2 (Correction):** Complete - All bugs fixed in commit 1759f8d
- ‚è≥ **FASE 3 (Proof of Life):** Aguardando execu√ß√£o no servidor

**Arquivo de Verifica√ß√£o:** `HDX-HUMANITARIAN-VERIFICATION.md` (this file)
**Commit:** 1759f8d - fix: hdx-humanitarian collector
