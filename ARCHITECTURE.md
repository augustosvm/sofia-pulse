# ğŸ—ï¸ Sofia Pulse - Arquitetura do Sistema

Este documento descreve a arquitetura completa do Sofia Pulse, incluindo componentes, fluxos de dados, decisÃµes de design e padrÃµes arquiteturais.

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Componentes Principais](#componentes-principais)
- [Fluxo de Dados](#fluxo-de-dados)
- [MÃ³dulos](#mÃ³dulos)
- [Database Design](#database-design)
- [SeguranÃ§a](#seguranÃ§a)
- [Escalabilidade](#escalabilidade)
- [Monitoramento](#monitoramento)
- [DecisÃµes de Design](#decisÃµes-de-design)

---

## ğŸ¯ VisÃ£o Geral

Sofia Pulse utiliza uma **arquitetura modular** baseada em:

- **Event-driven collection**: Coleta acionada por eventos (cron, webhooks)
- **Data lake approach**: Armazenamento raw + processado
- **MicroserviÃ§os light**: MÃ³dulos independentes mas integrados
- **API-first**: Todas funcionalidades expostas via API

### PrincÃ­pios Arquiteturais

1. **Separation of Concerns**: Cada mÃ³dulo tem responsabilidade Ãºnica
2. **Fail Fast**: Erros detectados e reportados rapidamente
3. **Idempotency**: Coletas podem ser re-executadas sem duplicaÃ§Ã£o
4. **Observability**: Logs, mÃ©tricas e tracing em todos os componentes
5. **Scalability**: Componentes escalÃ¡veis horizontalmente

---

## ğŸ§© Componentes Principais

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SOFIA PULSE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Collectors â”‚  â”‚  Processors â”‚  â”‚  Analyzers  â”‚            â”‚
â”‚  â”‚  (Coleta)   â”‚â”€â–¶â”‚ (Transform) â”‚â”€â–¶â”‚  (Insights) â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                 â”‚                 â”‚                   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                  â”‚   PostgreSQL    â”‚                            â”‚
â”‚                  â”‚    (sofia_db)   â”‚                            â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                           â”‚                                     â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚         â–¼                                   â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  REST API   â”‚                    â”‚  Dashboards â”‚            â”‚
â”‚  â”‚   (Future)  â”‚                    â”‚   (Grafana) â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. Collectors (Coletores)

**Responsabilidade**: Buscar dados de fontes externas

**CaracterÃ­sticas**:
- Um collector por fonte de dados
- Stateless (sem estado entre execuÃ§Ãµes)
- Retry logic com exponential backoff
- Rate limiting respeitado
- Data validation antes de persistir

**LocalizaÃ§Ã£o**: `scripts/collect-*.ts`

**Exemplo**:
```typescript
// scripts/collect-arxiv.ts
class ArXivCollector {
  async collect(since?: Date): Promise<Paper[]> {
    // 1. Fetch from ArXiv API
    // 2. Validate data
    // 3. Transform to internal format
    // 4. Return papers
  }

  async persist(papers: Paper[]): Promise<void> {
    // 1. Connect to DB
    // 2. Insert with UPSERT logic
    // 3. Log results
  }
}
```

### 2. Processors (Processadores)

**Responsabilidade**: Transformar e enriquecer dados

**CaracterÃ­sticas**:
- NormalizaÃ§Ã£o de dados
- Feature extraction
- Data cleaning
- Enrichment (adicionar metadata)

**LocalizaÃ§Ã£o**: `src/processors/`

**Exemplo**:
```typescript
// src/processors/paper-processor.ts
class PaperProcessor {
  extractKeywords(abstract: string): string[] {
    // NLP para extrair keywords
  }

  calculateRelevanceScore(paper: Paper): number {
    // Score baseado em citaÃ§Ãµes, autores, etc
  }

  enrichWithCitations(paper: Paper): EnrichedPaper {
    // Buscar citaÃ§Ãµes externas
  }
}
```

### 3. Analyzers (Analisadores)

**Responsabilidade**: Gerar insights e correlaÃ§Ãµes

**CaracterÃ­sticas**:
- CorrelaÃ§Ã£o multi-fonte
- Score computation
- Trend detection
- Anomaly detection

**LocalizaÃ§Ã£o**: `src/analyzers/`

**Exemplo**:
```typescript
// src/analyzers/innovation-analyzer.ts
class InnovationAnalyzer {
  async computeInnovationScore(company: string): Promise<Score> {
    const patents = await getPatents(company);
    const papers = await getPapers(company);
    const funding = await getFunding(company);

    return {
      score: this.weightedAverage([
        { value: patents.length, weight: 0.3 },
        { value: papers.length, weight: 0.2 },
        { value: funding.total, weight: 0.5 }
      ]),
      breakdown: { patents, papers, funding }
    };
  }
}
```

### 4. Database (PostgreSQL)

**Responsabilidade**: PersistÃªncia e queries

**CaracterÃ­sticas**:
- PostgreSQL 15+ com pgvector extension
- Indexes otimizados para queries comuns
- Partitioning por data em tabelas grandes
- Materialized views para agregaÃ§Ãµes

**Schema**: Ver [SCHEMA.md](docs/SCHEMA.md)

### 5. API Layer (Futuro)

**Responsabilidade**: Expor dados via REST/GraphQL

**CaracterÃ­sticas**:
- RESTful endpoints
- Authentication (JWT)
- Rate limiting
- Caching (Redis)
- API versioning

---

## ğŸ”„ Fluxo de Dados

### Coleta â†’ Armazenamento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ External â”‚
â”‚   API    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ HTTP Request
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Collector   â”‚
â”‚  - Fetch     â”‚
â”‚  - Validate  â”‚
â”‚  - Transform â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ Validated Data
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Processor   â”‚
â”‚  - Normalize â”‚
â”‚  - Enrich    â”‚
â”‚  - Clean     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ Processed Data
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL   â”‚
â”‚  INSERT/     â”‚
â”‚  UPSERT      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AnÃ¡lise â†’ Insights

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL   â”‚
â”‚  Raw Data    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ SQL Query
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Analyzer    â”‚
â”‚  - Correlate â”‚
â”‚  - Score     â”‚
â”‚  - Rank      â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ Insights
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Output     â”‚
â”‚  - JSON      â”‚
â”‚  - Dashboard â”‚
â”‚  - API       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AutomaÃ§Ã£o (Cron)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cron    â”‚
â”‚  Job     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ Scheduled Time
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  cron-*.sh   â”‚
â”‚  Script      â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ Execute
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Collectors   â”‚
â”‚ (sequential) â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ Data Collected
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Logger     â”‚
â”‚  - Success   â”‚
â”‚  - Errors    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ MÃ³dulos

### Module: Academia

**Fontes**: ArXiv, BDTD, SciELO

**Responsabilidades**:
- Coleta de papers, teses, artigos
- ExtraÃ§Ã£o de metadata cientÃ­fica
- Tracking de citaÃ§Ãµes
- IdentificaÃ§Ã£o de autores/instituiÃ§Ãµes

**Arquivos**:
```
scripts/
  collect-arxiv.ts
  collect-bdtd.ts
  collect-scielo.ts
src/processors/
  paper-processor.ts
  thesis-processor.ts
```

### Module: Innovation

**Fontes**: Clinical Trials, Patents

**Responsabilidades**:
- Coleta de ensaios clÃ­nicos
- Coleta de patentes
- Linking entre research â†’ patent
- Trend detection em inovaÃ§Ã£o

**Arquivos**:
```
scripts/
  collect-clinical-trials.ts
  collect-patents.ts
src/analyzers/
  innovation-analyzer.ts
```

### Module: Tech

**Fontes**: GitHub, Packages, StackOverflow

**Responsabilidades**:
- Tracking de repositÃ³rios trending
- Downloads de pacotes
- Tech problems detection (SO)
- Language/framework trends

**Arquivos**:
```
scripts/
  collect-github.ts
  collect-packages.ts
  collect-stackoverflow.ts
src/analyzers/
  tech-trends-analyzer.ts
```

### Module: Finance

**Fontes**: B3, NASDAQ, Funding Rounds

**Responsabilidades**:
- Coleta de aÃ§Ãµes/stocks
- Coleta de funding rounds
- GeraÃ§Ã£o de sinais de investimento
- CorrelaÃ§Ã£o research â†’ funding

**Arquivos**:
```
finance/
  scripts/
    collect-brazil-stocks.ts
    collect-nasdaq-momentum.ts
    collect-funding-rounds.ts
    generate-signals.ts
```

**DocumentaÃ§Ã£o**: Ver [finance/README.md](finance/README.md)

---

## ğŸ—„ï¸ Database Design

### Design Principles

1. **Normalization**: 3NF para evitar redundÃ¢ncia
2. **Denormalization**: Quando performance > storage
3. **Partitioning**: Por data em tabelas grandes (>10M rows)
4. **Indexing**: Indexes em foreign keys e campos de busca
5. **Constraints**: UNIQUE, NOT NULL, CHECK quando aplicÃ¡vel

### Schema Overview

```sql
-- Academia
arxiv_papers (id, arxiv_id, title, abstract, authors[], categories[], ...)
bdtd_theses (id, bdtd_id, title, author, university, ...)
scielo_articles (id, doi, title, journal, ...)

-- Innovation
clinical_trials (id, trial_id, sponsor, phase, ...)
patents (id, patent_number, assignee, inventors[], ...)

-- Tech
github_repos (id, repo_id, language, stars, ...)
software_packages (id, package_name, registry, downloads, ...)
stackoverflow_questions (id, question_id, tags[], score, ...)

-- Finance
market_data_brazil (id, ticker, price, change_pct, ...)
market_data_nasdaq (id, ticker, price, ...)
funding_rounds (id, company, amount_usd, valuation_usd, ...)
```

### Relationships

```
patents â”€â”€< assignee >â”€â”€ funding_rounds (company)
arxiv_papers â”€â”€< categories >â”€â”€ patents (classifications)
github_repos â”€â”€< language >â”€â”€ stackoverflow_questions (tags)
```

### Indexes Strategy

**Primary Indexes**:
- Todas tabelas: `id` (SERIAL PRIMARY KEY)
- External IDs: `UNIQUE` constraints

**Secondary Indexes**:
```sql
-- Busca por data
CREATE INDEX idx_arxiv_published ON arxiv_papers(published_date DESC);
CREATE INDEX idx_funding_announced ON funding_rounds(announced_date DESC);

-- Busca por empresa/company
CREATE INDEX idx_patents_assignee ON patents(assignee);
CREATE INDEX idx_funding_company ON funding_rounds(company);

-- Full-text search
CREATE INDEX idx_papers_fulltext ON arxiv_papers
  USING gin(to_tsvector('english', title || ' ' || abstract));
```

### Partitioning (Future)

Para tabelas grandes:

```sql
-- Particionar arxiv_papers por ano
CREATE TABLE arxiv_papers_2024 PARTITION OF arxiv_papers
  FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');

CREATE TABLE arxiv_papers_2025 PARTITION OF arxiv_papers
  FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');
```

---

## ğŸ”’ SeguranÃ§a

### Database Security

1. **Authentication**:
   - UsuÃ¡rio especÃ­fico `sofia` com permissÃµes limitadas
   - Senha forte (min 16 chars)
   - RotaÃ§Ã£o de senha a cada 90 dias

2. **Network**:
   - PostgreSQL nÃ£o exposto publicamente
   - Acesso apenas via Docker network
   - Whitelist de IPs se necessÃ¡rio

3. **Encryption**:
   - SSL/TLS para conexÃµes
   - Backups encriptados (gpg)
   - Dados sensÃ­veis hasheados

### API Security (Future)

1. **Authentication**: JWT tokens
2. **Authorization**: Role-based access control (RBAC)
3. **Rate Limiting**: Por IP e por usuÃ¡rio
4. **Input Validation**: SanitizaÃ§Ã£o de todos inputs
5. **CORS**: Whitelist de domÃ­nios

### Secrets Management

```bash
# Usar .env para secrets
# NUNCA commitar .env no git
.env        # Local secrets
.env.example # Template sem secrets
```

---

## ğŸ“ˆ Escalabilidade

### Horizontal Scaling

**Collectors**: ParalelizÃ¡veis
```bash
# Rodar mÃºltiplas instÃ¢ncias
docker-compose scale collector=5
```

**Database**: Read replicas
```yaml
# docker-compose.yml
postgres-primary:
  image: postgres:15
postgres-replica-1:
  image: postgres:15
  environment:
    POSTGRES_MASTER_SERVICE_HOST: postgres-primary
```

### Vertical Scaling

**Database tuning**:
```sql
-- postgresql.conf
shared_buffers = 4GB
work_mem = 256MB
maintenance_work_mem = 1GB
effective_cache_size = 12GB
max_connections = 200
```

### Caching Strategy

**Redis** para:
- API responses (TTL 5-60min)
- Trending queries results
- Rate limiting counters

```typescript
// Exemplo
const cached = await redis.get(`signals:${date}`);
if (cached) return JSON.parse(cached);

const signals = await generateSignals();
await redis.setex(`signals:${date}`, 3600, JSON.stringify(signals));
return signals;
```

### Queue System (Future)

**Bull/BullMQ** para:
- Processamento assÃ­ncrono
- Retry de jobs falhados
- PriorizaÃ§Ã£o de tarefas

```typescript
// Exemplo
const queue = new Queue('data-collection');

queue.add('collect-arxiv', { since: '2024-01-01' }, {
  priority: 1,
  attempts: 3,
  backoff: { type: 'exponential', delay: 2000 }
});
```

---

## ğŸ“Š Monitoramento

### Metrics

**Prometheus** para coletar:
- Request rate
- Error rate
- Response time
- Database connections
- Queue size

**Grafana** para visualizar:
- Dashboards customizados
- Alertas via Slack/Email
- SLA monitoring

### Logging

**Structured Logging**:
```typescript
logger.info('Collection completed', {
  source: 'arxiv',
  count: 150,
  duration: 45,
  timestamp: new Date()
});
```

**CentralizaÃ§Ã£o**:
- Logs salvos em `/var/log/sofia-*.log`
- RotaÃ§Ã£o diÃ¡ria (logrotate)
- RetenÃ§Ã£o: 30 dias

### Alerting

**Alertas crÃ­ticos**:
- Database down
- Coleta falhando por >24h
- Disk usage >80%
- Memory usage >90%

**Canais**:
- Telegram/Discord webhooks
- Email
- PagerDuty (produÃ§Ã£o)

---

## ğŸ§  DecisÃµes de Design

### Por que PostgreSQL?

âœ… **PrÃ³s**:
- ACID compliant
- Excelente para queries complexas (JOINs)
- pgvector para embeddings (future ML)
- Maturidade e comunidade

âŒ **Contras considerados**:
- NoSQL seria mais rÃ¡pido para writes
- Mas sacrificaria consistÃªncia

**DecisÃ£o**: ConsistÃªncia > Performance raw

### Por que TypeScript?

âœ… **PrÃ³s**:
- Type safety (menos bugs)
- Melhor DX (autocomplete, refactoring)
- Ecosistema npm rico

**Alternativas consideradas**:
- Python: Boa para ML, mas TypeScript better para infra
- Go: Performance, mas menos libs cientÃ­ficas

### Por que Cron vs Event-driven?

**Cron escolhido porque**:
- Maioria das fontes nÃ£o tem webhooks
- Polling Ã© necessÃ¡rio de qualquer forma
- Simplicidade operacional

**Future**: Hybrid (Cron + Webhooks quando disponÃ­vel)

### Por que Monorepo?

âœ… **PrÃ³s**:
- Compartilhamento de cÃ³digo (types, utils)
- Versionamento sincronizado
- CI/CD simplificado

âŒ **Contras**:
- Pode crescer muito
- Build times maiores

**MitigaÃ§Ã£o**: Module boundaries bem definidos

---

## ğŸ”® EvoluÃ§Ã£o Futura

### Fase 1: MVP (Atual)
- âœ… Coleta multi-fonte
- âœ… Armazenamento PostgreSQL
- âœ… Backup automatizado
- âœ… Finance module completo

### Fase 2: Intelligence (Q1 2025)
- [ ] API REST pÃºblica
- [ ] Dashboard Grafana completo
- [ ] Alertas automatizados
- [ ] Machine Learning bÃ¡sico

### Fase 3: Scale (Q2 2025)
- [ ] Kubernetes deployment
- [ ] Redis caching
- [ ] Queue system (Bull)
- [ ] Multi-region

### Fase 4: Platform (Q3-Q4 2025)
- [ ] Multi-tenancy
- [ ] Marketplace de sinais
- [ ] Mobile app
- [ ] Real-time streaming

---

## ğŸ“š ReferÃªncias

- [PostgreSQL Best Practices](https://wiki.postgresql.org/wiki/Performance_Optimization)
- [Node.js Production Best Practices](https://github.com/goldbergyoni/nodebestpractices)
- [Twelve-Factor App](https://12factor.net/)
- [Microservices Patterns](https://microservices.io/patterns/)

---

<p align="center">
  <strong>Arquitetura construÃ­da para escalar de MVP a plataforma enterprise</strong>
</p>
