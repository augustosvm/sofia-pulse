# ðŸ†“ Ferramentas GRATUITAS para Data Mining - Sofia Pulse

**Objetivo**: Gerar insights dos ~970 registros (29 tabelas) SEM pagar por APIs.

---

## ðŸŽ¯ EstratÃ©gia: 3 Camadas de AnÃ¡lise

### 1. **AnÃ¡lise EstatÃ­stica AutomÃ¡tica** (Sem IA)
   - CorrelaÃ§Ãµes, anomalias, tendÃªncias
   - Completamente grÃ¡tis, rÃ¡pido

### 2. **Machine Learning Local** (PostgreSQL)
   - Clustering, regressÃ£o, classificaÃ§Ã£o
   - Roda dentro do PostgreSQL, sem custos

### 3. **LLM Local** (Opcional, para narrativas)
   - Ollama + Llama 3.2 (3B)
   - Roda 100% local, sem internet, grÃ¡tis

---

## ðŸ“Š CAMADA 1: AnÃ¡lise EstatÃ­stica (Sempre Funciona)

### Ferramentas Python (JÃ¡ no Setup):

#### **Pandas Profiling** - EDA AutomÃ¡tico
```bash
pip install ydata-profiling
```

**O que faz**:
- Gera relatÃ³rio HTML completo de TODOS os dados
- CorrelaÃ§Ãµes automÃ¡ticas
- Valores faltantes, outliers
- DistribuiÃ§Ãµes, histogramas

**Exemplo**:
```python
from ydata_profiling import ProfileReport

# Carregar TODOS os dados do banco
all_data = pd.read_sql("SELECT * FROM sofia.market_data_brazil", engine)

# Gerar relatÃ³rio automÃ¡tico
profile = ProfileReport(all_data, title="Sofia Pulse - B3 Analysis")
profile.to_file("reports/b3-analysis.html")
```

**Resultado**: RelatÃ³rio HTML com 50+ anÃ¡lises automÃ¡ticas!

---

#### **Sweetviz** - ComparaÃ§Ãµes AutomÃ¡ticas
```bash
pip install sweetviz
```

**O que faz**:
- Compara datasets (ex: B3 vs NASDAQ)
- AnÃ¡lise visual automÃ¡tica
- Detecta correlaÃ§Ãµes entre tabelas

**Exemplo**:
```python
import sweetviz as sv

b3 = pd.read_sql("SELECT * FROM sofia.market_data_brazil", engine)
nasdaq = pd.read_sql("SELECT * FROM sofia.market_data_nasdaq", engine)

# Comparar mercados
report = sv.compare([b3, "B3"], [nasdaq, "NASDAQ"])
report.show_html("reports/b3-vs-nasdaq.html")
```

---

#### **D-Tale** - ExploraÃ§Ã£o Interativa
```bash
pip install dtale
```

**O que faz**:
- Dashboard web interativo
- Filtros, correlaÃ§Ãµes, grÃ¡ficos
- Exporta insights para cÃ³digo

**Exemplo**:
```python
import dtale

# Carregar dados
data = pd.read_sql("SELECT * FROM sofia.funding_rounds", engine)

# Abrir dashboard interativo
d = dtale.show(data)
d.open_browser()
```

**Acessa**: http://localhost:40000

---

## ðŸ¤– CAMADA 2: Machine Learning no PostgreSQL

### **Apache MADlib** - ML dentro do PostgreSQL

**O que Ã©**: Biblioteca de ML que roda SQL queries diretamente no banco.

**InstalaÃ§Ã£o** (Docker):
```bash
# MADlib jÃ¡ vem em algumas imagens PostgreSQL
# Ou instalar extensÃ£o:
docker exec -it sofia-postgres psql -U sofia -d sofia_db -c "CREATE EXTENSION madlib;"
```

**Capacidades**:
- RegressÃ£o linear/logÃ­stica
- K-Means clustering
- Decision Trees
- PCA (reduÃ§Ã£o dimensionalidade)
- AnÃ¡lise de sÃ©ries temporais

**Exemplo - Clustering de Setores**:
```sql
-- Criar tabela de features
CREATE TABLE sector_features AS
SELECT
  sector,
  AVG(change_pct) as avg_performance,
  SUM(volume) as total_volume,
  COUNT(*) as num_companies
FROM sofia.market_data_brazil
GROUP BY sector;

-- Rodar K-Means (3 clusters)
SELECT madlib.kmeans(
  'sector_features',           -- tabela
  'sector_clusters',           -- output
  'avg_performance,total_volume', -- features
  3                            -- num clusters
);

-- Ver resultados
SELECT * FROM sector_clusters;
```

**Resultado**: Setores agrupados por performance/volume (ex: "High Growth", "Stable", "Declining")

---

### **PostgreSQL pg_stat_statements** - Query Analytics

**O que faz**: Rastreia patterns de acesso aos dados.

**Exemplo**:
```sql
-- Ver queries mais lentas (otimizar)
SELECT query, mean_exec_time, calls
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;
```

---

## ðŸ§  CAMADA 3: LLM Local (Ollama)

### **Ollama** - Rodar Llama/Mistral localmente

**O que Ã©**: Roda modelos de IA 100% no seu computador, sem internet, grÃ¡tis.

**InstalaÃ§Ã£o**:
```bash
# Linux
curl -fsSL https://ollama.com/install.sh | sh

# Baixar modelo Llama 3.2 (3B - leve)
ollama pull llama3.2:3b

# Testar
ollama run llama3.2:3b "Hello!"
```

**Uso no Python**:
```bash
pip install ollama
```

```python
import ollama

# Gerar insights a partir de dados
data_summary = f"""
B3 (Brasil): 64 stocks, mÃ©dia +1.63%
NASDAQ: 24 stocks, mÃ©dia +0.85%
Funding: $17.3B investidos, AI sector lidera

Encontre correlaÃ§Ãµes e oportunidades.
"""

response = ollama.chat(model='llama3.2:3b', messages=[
  {'role': 'user', 'content': data_summary}
])

print(response['message']['content'])
```

**Resultado**: Narrativas e insights gerados localmente!

**Modelos Recomendados**:
- `llama3.2:3b` - Leve, rÃ¡pido, ~2GB RAM
- `mistral:7b` - Melhor qualidade, ~4GB RAM
- `phi3:mini` - Muito leve, ~2GB RAM

---

## ðŸ“¦ ExtensÃµes PostgreSQL para "Data Lake"

### **FDW (Foreign Data Wrappers)** - Acessar mÃºltiplas fontes

**O que faz**: Conecta PostgreSQL a outras fontes (CSV, MongoDB, APIs) como se fossem tabelas.

**InstalaÃ§Ã£o**:
```bash
docker exec -it sofia-postgres psql -U sofia -d sofia_db
```

```sql
-- Habilitar FDW
CREATE EXTENSION file_fdw;

-- Acessar CSV como tabela
CREATE SERVER csv_server FOREIGN DATA WRAPPER file_fdw;

CREATE FOREIGN TABLE external_data (
  date DATE,
  value NUMERIC
)
SERVER csv_server
OPTIONS (filename '/data/external.csv', format 'csv', header 'true');

-- Query como tabela normal
SELECT * FROM external_data;
```

---

### **pg_analytics** - OLAP no PostgreSQL

**O que Ã©**: Transforma PostgreSQL em data warehouse (DuckDB integrado).

**InstalaÃ§Ã£o**:
```bash
# Adicionar extensÃ£o
docker exec -it sofia-postgres psql -U sofia -d sofia_db -c "CREATE EXTENSION pg_analytics;"
```

**Uso**:
```sql
-- Queries OLAP otimizadas
SELECT
  sector,
  date_trunc('month', collected_at) as month,
  SUM(amount_usd) as total_funding
FROM sofia.funding_rounds
GROUP BY sector, month
ORDER BY month, total_funding DESC;
```

---

### **TimescaleDB** - SÃ©ries Temporais

**O que faz**: Otimiza PostgreSQL para dados de tempo (preÃ§os, volumes).

**InstalaÃ§Ã£o**:
```bash
docker exec -it sofia-postgres psql -U sofia -d sofia_db -c "CREATE EXTENSION timescaledb;"
```

**Uso**:
```sql
-- Converter tabela para hypertable (otimizada)
SELECT create_hypertable('sofia.market_data_brazil', 'collected_at');

-- Queries otimizadas
SELECT
  time_bucket('1 day', collected_at) AS day,
  ticker,
  AVG(price) as avg_price
FROM sofia.market_data_brazil
WHERE collected_at > NOW() - INTERVAL '30 days'
GROUP BY day, ticker;
```

---

## ðŸš€ Stack Recomendado (100% GrÃ¡tis)

### MÃ­nimo (RÃ¡pido):
```bash
pip install ydata-profiling sweetviz dtale
```
â†’ RelatÃ³rios HTML automÃ¡ticos em 5min

### Completo (Melhor):
```bash
# Python
pip install ydata-profiling sweetviz dtale ollama

# PostgreSQL Extensions
docker exec -it sofia-postgres psql -U sofia -d sofia_db
CREATE EXTENSION madlib;      -- ML
CREATE EXTENSION file_fdw;    -- Data lake
CREATE EXTENSION timescaledb; -- Time series

# Ollama (LLM local)
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3.2:3b
```

---

## ðŸ“‹ Workflow Completo

### 1. EDA AutomÃ¡tico (Pandas Profiling)
```python
from ydata_profiling import ProfileReport

all_tables = ['market_data_brazil', 'market_data_nasdaq', 'funding_rounds']
for table in all_tables:
    df = pd.read_sql(f"SELECT * FROM sofia.{table}", engine)
    profile = ProfileReport(df, title=f"Sofia - {table}")
    profile.to_file(f"reports/{table}-analysis.html")
```

**Output**: 3 relatÃ³rios HTML com anÃ¡lise completa.

---

### 2. CorrelaÃ§Ãµes Cross-Table (SQL)
```sql
-- Funding vs Performance
WITH funding_by_sector AS (
  SELECT sector, SUM(amount_usd) as total_funding
  FROM sofia.funding_rounds
  GROUP BY sector
),
performance_by_sector AS (
  SELECT sector, AVG(change_pct) as avg_performance
  FROM sofia.market_data_brazil
  GROUP BY sector
)
SELECT
  f.sector,
  f.total_funding / 1000000000.0 as funding_billions,
  p.avg_performance,
  CORR(f.total_funding, p.avg_performance) OVER () as correlation
FROM funding_by_sector f
JOIN performance_by_sector p ON f.sector = p.sector;
```

---

### 3. Clustering (MADlib)
```sql
-- Agrupar empresas por caracterÃ­sticas
SELECT madlib.kmeans(
  'market_data_brazil',
  'company_clusters',
  'price,volume,change_pct',
  3
);

SELECT cluster_id, COUNT(*), AVG(change_pct)
FROM company_clusters
GROUP BY cluster_id;
```

---

### 4. Narrativa (Ollama)
```python
import ollama

clusters = pd.read_sql("SELECT * FROM company_clusters", engine)
summary = f"Cluster 0: {clusters[0].describe()}\n..."

insights = ollama.chat(model='llama3.2:3b', messages=[
  {'role': 'user', 'content': f'Analise estes clusters:\n{summary}'}
])

print(insights['message']['content'])
```

---

## ðŸ’¾ Estrutura de Outputs

```
analytics/
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ market_data_brazil-analysis.html      # Pandas Profiling
â”‚   â”œâ”€â”€ market_data_nasdaq-analysis.html
â”‚   â”œâ”€â”€ funding_rounds-analysis.html
â”‚   â”œâ”€â”€ b3-vs-nasdaq-comparison.html          # Sweetviz
â”‚   â””â”€â”€ correlation-matrix.png                # Matplotlib
â”œâ”€â”€ insights/
â”‚   â”œâ”€â”€ sector-clusters.csv                   # K-Means output
â”‚   â”œâ”€â”€ anomalies-detected.csv                # Outliers
â”‚   â”œâ”€â”€ time-series-forecast.csv              # Prophet
â”‚   â””â”€â”€ ai-insights.txt                       # Ollama narratives
â””â”€â”€ notebooks/
    â”œâ”€â”€ exploratory-analysis.ipynb            # Jupyter
    â””â”€â”€ correlation-study.ipynb
```

---

## âš¡ Quick Start (Agora!)

```bash
cd ~/sofia-pulse

# 1. Instalar ferramentas bÃ¡sicas (5min)
source venv-analytics/bin/activate
pip install ydata-profiling sweetviz dtale

# 2. Gerar primeiro relatÃ³rio (2min)
python3 << 'EOF'
import pandas as pd
from sqlalchemy import create_engine
from ydata_profiling import ProfileReport

engine = create_engine('postgresql://sofia:sofia123strong@localhost:5432/sofia_db')
df = pd.read_sql("SELECT * FROM sofia.market_data_brazil", engine)

profile = ProfileReport(df, title="Sofia Pulse - B3 Analysis")
profile.to_file("analytics/reports/b3-auto-analysis.html")
print("âœ… RelatÃ³rio gerado: analytics/reports/b3-auto-analysis.html")
EOF

# 3. Abrir no browser
xdg-open analytics/reports/b3-auto-analysis.html
```

**Resultado**: RelatÃ³rio completo de B3 em HTML, 100% grÃ¡tis, sem IA paga!

---

## ðŸ†š ComparaÃ§Ã£o: Claude (Pago) vs GrÃ¡tis

| Feature | Claude API (Pago) | Ferramentas GrÃ¡tis |
|---------|-------------------|-------------------|
| **EDA** | âŒ NÃ£o faz | âœ… Pandas Profiling (melhor) |
| **CorrelaÃ§Ãµes** | âœ… Identifica | âœ… SQL + Pandas (igual) |
| **Clustering** | âŒ NÃ£o faz | âœ… MADlib + Scikit-learn |
| **Narrativas** | âœ… Excelente | âœ… Ollama (bom, local) |
| **Custo** | $$$$ | **$0** |
| **Privacidade** | âŒ Envia dados | âœ… 100% local |
| **Velocidade** | ~10s/request | âš¡ InstantÃ¢neo (SQL/Pandas) |

---

## ðŸŽ¯ RecomendaÃ§Ã£o Final

**Para Sofia Pulse**, use:

1. **Pandas Profiling** â†’ RelatÃ³rios automÃ¡ticos
2. **SQL queries** â†’ CorrelaÃ§Ãµes e agregaÃ§Ãµes
3. **MADlib** â†’ Clustering e ML (se precisar)
4. **Ollama** â†’ Narrativas (opcional, sÃ³ se tiver GPU/RAM)

**NÃ£o precisa de Claude** para maioria dos insights. SQL + Pandas + Profiling jÃ¡ resolve 90%!

---

## ðŸ“š Recursos

- Pandas Profiling: https://github.com/ydataai/ydata-profiling
- Sweetviz: https://github.com/fbdesignpro/sweetviz
- D-Tale: https://github.com/man-group/dtale
- MADlib: https://madlib.apache.org/
- Ollama: https://ollama.com/
- TimescaleDB: https://docs.timescale.com/

---

**PrÃ³ximo Passo**: Rodar `setup-data-mining-free.sh` (sem dependÃªncias pagas)!
